{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import polars as pl\n",
    "import inspect\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import dsds.metrics as me\n",
    "import dsds.prescreen as ps\n",
    "import dsds.sample as sa\n",
    "import dsds.fs as fs\n",
    "import dsds.transform as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>Daily Time Spent on Site</th><th>Age</th><th>Area Income</th><th>Daily Internet Usage</th><th>Ad Topic Line</th><th>City</th><th>Male</th><th>Country</th><th>Timestamp</th><th>Clicked on Ad</th><th>One_Hot_Test</th><th>Age Band</th><th>Daily Internet Usage Band</th><th>Area Income Band</th><th>Test_Constant</th><th>Test_Str_Constant</th><th>Test_BadColumn</th><th>Test_Binary</th></tr><tr><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>68.95</td><td>35</td><td>61833.9</td><td>256.09</td><td>&quot;Cloned 5thgene…</td><td>&quot;Wrightburgh&quot;</td><td>0</td><td>&quot;Tunisia&quot;</td><td>&quot;3/27/2016 0:53…</td><td>0</td><td>&quot;A&quot;</td><td>30</td><td>12</td><td>12</td><td>1</td><td>&quot;SSS&quot;</td><td>0</td><td>&quot;A&quot;</td></tr><tr><td>2</td><td>80.23</td><td>31</td><td>68441.85</td><td>193.77</td><td>&quot;Monitored nati…</td><td>&quot;West Jodi&quot;</td><td>1</td><td>&quot;Nauru&quot;</td><td>&quot;4/4/2016 1:39&quot;</td><td>0</td><td>&quot;B&quot;</td><td>30</td><td>9</td><td>13</td><td>1</td><td>&quot;SSS&quot;</td><td>null</td><td>&quot;B&quot;</td></tr><tr><td>3</td><td>69.47</td><td>26</td><td>59785.94</td><td>236.5</td><td>&quot;Organic bottom…</td><td>&quot;Davidton&quot;</td><td>0</td><td>&quot;San Marino&quot;</td><td>&quot;3/13/2016 20:3…</td><td>0</td><td>&quot;A&quot;</td><td>20</td><td>11</td><td>11</td><td>1</td><td>&quot;SSS&quot;</td><td>0</td><td>&quot;A&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 19)\n",
       "┌─────┬─────────────┬─────┬─────────────┬───┬─────────────┬─────────────┬─────────────┬────────────┐\n",
       "│ id  ┆ Daily Time  ┆ Age ┆ Area Income ┆ … ┆ Test_Consta ┆ Test_Str_Co ┆ Test_BadCol ┆ Test_Binar │\n",
       "│ --- ┆ Spent on    ┆ --- ┆ ---         ┆   ┆ nt          ┆ nstant      ┆ umn         ┆ y          │\n",
       "│ i64 ┆ Site        ┆ i64 ┆ f64         ┆   ┆ ---         ┆ ---         ┆ ---         ┆ ---        │\n",
       "│     ┆ ---         ┆     ┆             ┆   ┆ i64         ┆ str         ┆ i64         ┆ str        │\n",
       "│     ┆ f64         ┆     ┆             ┆   ┆             ┆             ┆             ┆            │\n",
       "╞═════╪═════════════╪═════╪═════════════╪═══╪═════════════╪═════════════╪═════════════╪════════════╡\n",
       "│ 1   ┆ 68.95       ┆ 35  ┆ 61833.9     ┆ … ┆ 1           ┆ SSS         ┆ 0           ┆ A          │\n",
       "│ 2   ┆ 80.23       ┆ 31  ┆ 68441.85    ┆ … ┆ 1           ┆ SSS         ┆ null        ┆ B          │\n",
       "│ 3   ┆ 69.47       ┆ 26  ┆ 59785.94    ┆ … ┆ 1           ┆ SSS         ┆ 0           ┆ A          │\n",
       "└─────┴─────────────┴─────┴─────────────┴───┴─────────────┴─────────────┴─────────────┴────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_csv(\"../data/advertising.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsds._rust import rs_cnt_vectorizer, rs_get_stem_table, rs_snowball_stem\n",
    "import dsds.test_text as tt\n",
    "c = \"Ad Topic Line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.22 ms ± 233 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df2 = rs_cnt_vectorizer(df, c, r'[^\\s\\w\\d%]', 0.02, 0.95, 2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.4 ms ± 733 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df3 = tt.count_vectorizer(df, c, tokenizer=\" \", min_dfreq=0.02, max_dfreq=0.95, max_features=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = df[c].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_df=0.95, min_df=0.02)\n",
    "X = np.array(vectorizer.fit_transform(corpus).todense())\n",
    "cols = vectorizer.get_feature_names_out().tolist()\n",
    "df_words = pl.from_numpy(X, schema=cols)\n",
    "df_combined = pl.concat([df, df_words], how=\"horizontal\")\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"system\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (17, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>stemmed</th><th>Ad Topic Line</th><th>doc_freq</th></tr><tr><td>str</td><td>list[str]</td><td>f32</td></tr></thead><tbody><tr><td>&quot;interfac&quot;</td><td>[&quot;interface&quot;]</td><td>0.033</td></tr><tr><td>&quot;secur&quot;</td><td>[&quot;secured&quot;]</td><td>0.023</td></tr><tr><td>&quot;analyz&quot;</td><td>[&quot;analyzer&quot;, &quot;analyzing&quot;]</td><td>0.02</td></tr><tr><td>&quot;system&quot;</td><td>[&quot;system&quot;, &quot;systemic&quot;]</td><td>0.036</td></tr><tr><td>&quot;implement&quot;</td><td>[&quot;implemented&quot;, &quot;implementation&quot;]</td><td>0.021</td></tr><tr><td>&quot;user&quot;</td><td>[&quot;user&quot;]</td><td>0.024</td></tr><tr><td>&quot;solut&quot;</td><td>[&quot;solution&quot;]</td><td>0.029</td></tr><tr><td>&quot;local&quot;</td><td>[&quot;local&quot;]</td><td>0.023</td></tr><tr><td>&quot;network&quot;</td><td>[&quot;network&quot;, &quot;networked&quot;]</td><td>0.022</td></tr><tr><td>&quot;optim&quot;</td><td>[&quot;optimized&quot;, &quot;optimizing&quot;, &quot;optimal&quot;]</td><td>0.025</td></tr><tr><td>&quot;focus&quot;</td><td>[&quot;focus&quot;, &quot;focused&quot;]</td><td>0.023</td></tr><tr><td>&quot;frontlin&quot;</td><td>[&quot;frontline&quot;]</td><td>0.02</td></tr><tr><td>&quot;zero&quot;</td><td>[&quot;zero&quot;]</td><td>0.022</td></tr><tr><td>&quot;structur&quot;</td><td>[&quot;structure&quot;]</td><td>0.02</td></tr><tr><td>&quot;monitor&quot;</td><td>[&quot;monitored&quot;, &quot;monitoring&quot;]</td><td>0.022</td></tr><tr><td>&quot;manag&quot;</td><td>[&quot;management&quot;, &quot;managed&quot;]</td><td>0.029</td></tr><tr><td>&quot;graphic&quot;</td><td>[&quot;graphical&quot;, &quot;graphic&quot;]</td><td>0.026</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (17, 3)\n",
       "┌──────────┬─────────────────────────────┬──────────┐\n",
       "│ stemmed  ┆ Ad Topic Line               ┆ doc_freq │\n",
       "│ ---      ┆ ---                         ┆ ---      │\n",
       "│ str      ┆ list[str]                   ┆ f32      │\n",
       "╞══════════╪═════════════════════════════╪══════════╡\n",
       "│ interfac ┆ [\"interface\"]               ┆ 0.033    │\n",
       "│ secur    ┆ [\"secured\"]                 ┆ 0.023    │\n",
       "│ analyz   ┆ [\"analyzer\", \"analyzing\"]   ┆ 0.02     │\n",
       "│ system   ┆ [\"system\", \"systemic\"]      ┆ 0.036    │\n",
       "│ …        ┆ …                           ┆ …        │\n",
       "│ structur ┆ [\"structure\"]               ┆ 0.02     │\n",
       "│ monitor  ┆ [\"monitored\", \"monitoring\"] ┆ 0.022    │\n",
       "│ manag    ┆ [\"management\", \"managed\"]   ┆ 0.029    │\n",
       "│ graphic  ┆ [\"graphical\", \"graphic\"]    ┆ 0.026    │\n",
       "└──────────┴─────────────────────────────┴──────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_get_stem_table(df, c, '[^\\s\\w\\d%]', 0.02, 0.95, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Ad Topic Line::cnt_system\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Ad Topic Line::cnt_analyz\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = pl.from_numpy(X, schema=cols)\n",
    "df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"../data/advertising.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dsds.metrics as me\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def pure_numpy_logloss(y_actual:np.ndarray, y_predict:np.ndarray):\n",
    "    return -np.mean(y_actual * np.log(y_predict) + (1 - y_actual) * np.log(1 - y_predict))\n",
    "\n",
    "pred = np.random.random(size=500_000) # Some random fake predictions\n",
    "actual = np.round(np.random.random(size=500_000)).astype(np.int8) # Some random fake actual labels\n",
    "# Yielding the same result up to 12 digits\n",
    "print(round(me.logloss(actual, pred), 12) == round(log_loss(actual, pred), 12))\n",
    "print(round(me.logloss(actual, pred), 12) == round(pure_numpy_logloss(actual, pred), 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "me.logloss(actual, pred) # dsds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "log_loss(actual, pred) # sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "pure_numpy_logloss(actual, pred) # pure numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_classification\n",
    "# orig_x, orig_y = make_classification(n_samples = 100_000, n_features = 10, n_informative = 5, n_redundant = 5)\n",
    "# # This is a Polars dataframe. This is dsds package's favored dataframe. dsds relies on Polars heavily.\n",
    "# # You must turn other dataframe formats into Polars for dsds to work.\n",
    "# df = pl.from_numpy(orig_x).insert_at_idx(0, pl.Series(\"target\", orig_y)) \n",
    "# # Turn it into Pandas.\n",
    "# df_pd = df.to_pandas()\n",
    "# target = \"target\"\n",
    "# features = df.columns\n",
    "# features.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"a\": [1, np.nan, None],\n",
    "    \"b\": [1,2,3]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.invalid_inferral(df, threshold=0.5, include_null=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.discrete_inferral(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ps.get_unique_count(df.with_row_count(offset=1).set_sorted(\"row_nr\"), include_null_count=True)\n",
    "len_df = temp.filter(pl.col(\"column\") == \"row_nr\").item(0,1)\n",
    "print(len_df)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "orig_x, orig_y = make_classification(n_samples = 50_000, n_features = 50, n_informative = 20, n_redundant = 30)\n",
    "df_pl = pl.from_numpy(orig_x).insert_at_idx(0, pl.Series(\"target\", orig_y))\n",
    "features = df_pl.columns\n",
    "features.remove(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in sa.time_series_split(df_pl, n_splits=5, offset = 1000):\n",
    "    print(train.shape)\n",
    "    print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "fs.discrete_ig(df_pl, target=\"target\", cols=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "fs.discrete_ig2(df_pl, target=\"target\", cols=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "me.logloss(actual, pred, check_binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
