{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import polars as pl\n",
    "import inspect\n",
    "import numpy as np\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.random.random(size=100_000) # .reshape(-1, 1) # Predictions\n",
    "actual = np.round(np.random.random(size=100_000)).astype(np.int8)  # Actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tp_fp(y_actual:np.ndarray, y_predicted:np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "\n",
    "    df = pl.from_records((y_predicted, y_actual), schema=[\"predicted\", \"actual\"])\n",
    "    all_positives = pl.lit(np.sum(y_actual))\n",
    "    temp = df.lazy().groupby(\"predicted\").agg(\n",
    "        pl.col(\"actual\").sum().alias(\"true_positive\")\n",
    "    ).sort(\"predicted\").with_columns(\n",
    "        predicted_positive = pl.arange(start=len(y_actual), end=1, step=-1)\n",
    "        , tp = (all_positives - pl.col(\"true_positive\").cumsum()).shift_and_fill(fill_value=all_positives, periods=1)\n",
    "    ).select(\n",
    "        pl.col(\"predicted\")\n",
    "        , pl.col(\"tp\")\n",
    "        , fp = pl.col(\"predicted_positive\") - pl.col(\"tp\")\n",
    "    ).collect()\n",
    "    # We are relatively sure that y_actual and y_predicted won't have null values.\n",
    "    # So we can do temp[\"tp\"].view() to get some more performance (3-8%). \n",
    "    # But that might confuse users.\n",
    "    return temp[\"tp\"].to_numpy(), temp[\"fp\"].to_numpy(), temp[\"predicted\"].to_numpy()\n",
    "\n",
    "def roc_auc(y_actual:np.ndarray, y_predicted:np.ndarray) -> float:\n",
    "\n",
    "    y_a = y_actual.ravel()\n",
    "    y_p = y_predicted.ravel()\n",
    "    if len(y_a) != len(y_p):\n",
    "        pass\n",
    "\n",
    "    uniques = np.unique(y_a)\n",
    "    if uniques.size != 2:\n",
    "        pass\n",
    "    elif not (0 in uniques or 1 in uniques):\n",
    "        pass\n",
    "\n",
    "    tp, fp, _ = get_tp_fp(y_a.astype(np.int8), y_p)\n",
    "    tpr = tp/tp[0]\n",
    "    fpr = fp/fp[0]\n",
    "    return float(-np.trapz(tpr, fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "roc_auc(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "roc_auc_score(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "roc_auc(actual, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1, _, thresholds = roc_curve(actual, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "roc_auc_score(actual, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc(actual, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(actual, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = (np.arange(0,100,1)/100)\n",
    "base = np.full(shape=(50_000, 100), fill_value=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base1 = np.full(shape=(50_000, 100), fill_value=False)\n",
    "for i in range(50_000):\n",
    "    base1[i, :] = grid.ravel() < a[i]\n",
    "\n",
    "base1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base2 = grid < a\n",
    "base2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(base1 == base2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.random.random(size=100_000) # .reshape(-1, 1) # Predictions\n",
    "actual = np.random.random(size=100_000)  # Actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9798763642620925"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "diff1 = actual - pred\n",
    "ss_res = diff1.dot(diff1)\n",
    "diff2 = actual - np.mean(actual)\n",
    "ss_tot = diff2.dot(diff2)\n",
    "ans = 1 - ss_res/ss_tot\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14 ms ± 25.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "ss_res = np.sum(np.square(actual - pred))\n",
    "ss_tot = np.sum(np.square(actual - np.mean(actual)))\n",
    "ans = 1 - ss_res/ss_tot\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "rng = np.random.default_rng()\n",
    "sample1 = stats.uniform.rvs(size=100, random_state=rng)\n",
    "sample2 = stats.norm.rvs(size=110, random_state=rng)\n",
    "res = stats.ks_2samp(sample1, sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pl.DataFrame({\"a\": range(20)}).lazy() # .to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby((pl.col(\"a\") < 10).alias(\"is_smaller\")).agg(\n",
    "    pl.all().first()\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"a\":[\"x\", \"y\", \"z\"]\n",
    "    , \"num\":[1,2,3]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pl.DataFrame({\n",
    "    \"a\":[\"x\", \"y\", \"z\"]\n",
    "    ,\"to\":[3,2,1]\n",
    "})\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.join(mapping, on=\"a\").with_columns(\n",
    "    pl.col(\"to\").alias(\"a\")\n",
    ").drop(\"to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import random \n",
    "\n",
    "df = pl.scan_csv(\"../data/test.csv\")\n",
    "    \n",
    "# Define polars custom functions to apply\n",
    "def add_position_column(df:pl.LazyFrame):\n",
    "    df = df.with_columns( \n",
    "        pl.when(pl.col('defensive_skill') > 50).then('CB')\n",
    "        .when(pl.col('offensive_skill') > 50).then('FW')\n",
    "        .otherwise('bench').alias(\"position\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def add_squad_number_column(df:pl.LazyFrame):\n",
    "    df = df.with_columns( \n",
    "        pl.when(pl.col('position') == 'CD').then(pl.lit(random.sample(range(2, 6), 1)[0], dtype=pl.Int8))\n",
    "        .when(pl.col('position') == 'FW').then(pl.lit(random.sample(range(7, 19), 1)[0], dtype=pl.Int8))\n",
    "        .otherwise('-').alias(\"squad_number\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Chain operations together using the pipe function\n",
    "\n",
    "\n",
    "df.pipe(add_position_column)\\\n",
    "    .pipe(add_squad_number_column)\\\n",
    "    .write_json(\"pipe.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"pipe.json\", \"r\")\n",
    "json_str = f.read()\n",
    "f.close()\n",
    "df3 = pl.read_csv(\"../data/test.csv\")\n",
    "df2 = df3.lazy().from_json(json_str)\n",
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = pl.LazyFrame().from_json(json_str)\n",
    "plan.write_json(\"pipe.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"a\",\"b\"]\n",
    "\n",
    "\"|\".join(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test() -> list[str]:\n",
    "    return [\"a\"]\n",
    "\n",
    "test.__annotations__.get(\"return\", \"\") == list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Concatenate\n",
    "\n",
    "tt:Callable[[], list]\n",
    "tt = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect.signature(tt).return_annotation == \"list[str]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"g\": list(range(1000))\n",
    "}).lazy()\n",
    "\n",
    "# test = pl.Series(\"x\",[\"a\", \"b\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df = pl.LazyFrame((list(range(1000)), list(i*2 for i in range(1000))), schema=[\"g\", \"g_mapped\"])\n",
    "join_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "df.with_columns(\n",
    "    pl.col(\"g\").map_dict({i:2*i for i in range(1000)})\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "df.join(join_df, on = \"g\").with_columns(\n",
    "    pl.col(\"g_mapped\").alias(\"g\")\n",
    ").drop(columns=[\"g_mapped\"]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.join(join_df, on = \"g\").with_columns(\n",
    "    pl.col(\"g_mapped\").alias(\"g\")\n",
    ").drop(columns=[\"g_mapped\"]).write_json(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"a\": list(range(1000)),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator, Tuple, Any\n",
    "\n",
    "mapping = {i:i for i in range(1000)}\n",
    "test = mapping.copy()\n",
    "cname = \"a\"\n",
    "def create_map_expr(\n",
    "        col_name:str\n",
    "        , gen:Generator[Tuple[str, Any], None, None]\n",
    "        , default:Any = None\n",
    ") -> pl.Expr:\n",
    "\n",
    "    '''\n",
    "        Suppose you have a dictionary like d = {\"a\":1, \"b\":2}. Instead of doing pl.col(\"column\").map_dict(d), you can \n",
    "        do pl.when(pl.col(\"column\") == \"a\").then(1).otherwise(pl.when(pl.col(\"column\") == \"b\").then(2).otherwise(default))\n",
    "        instead. This function generators this expression for you from a generator that yields a key value pair.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        k, v = next(gen)\n",
    "        return pl.when(pl.col(col_name) == k).then(v).otherwise(create_map_expr(col_name, gen))\n",
    "    except:\n",
    "        return pl.lit(default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "df.select(\n",
    "    pl.col(\"a\").map_dict(mapping)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = list(range(1000))\n",
    "expr = create_map_expr(cname, zip(m, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "\n",
    "df.select(\n",
    "    expr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\"a\":[None, 1,2,3,4,5,6,7], \"b\":[1,2,1,1,1,1,1,1]})\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lazy().groupby(1).agg(\n",
    "        pl.col(s).unique().sort() for s in df.columns\n",
    "    ).select(df.columns).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\"asdbdasbfa\" + \"abdsbads\" + \"asdffkilo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(100))\n",
    "b = range(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "a.extend(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "df_metrics = df.lazy().select(\n",
    "    pl.all().min().prefix(\"min:\"),\n",
    "    pl.all().max().prefix(\"max:\")\n",
    ").collect().row(0) # .row(0)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "mins = df.lazy().select(\n",
    "    pl.all().min().prefix(\"min:\")\n",
    ").collect().to_numpy().ravel()\n",
    "maxs = df.lazy().select(\n",
    "    pl.all().max().prefix(\"max:\")\n",
    ").collect().to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "a.extend(range(5,10))\n",
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute error, because pl.col(c) returns columns of different len depending on unique values\n",
    "df.select(\n",
    "    pl.col(c).unique().sort() for c in df.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = df.lazy().groupby(1).agg(\n",
    "    pl.col(c).unique().sort() for c in df.columns\n",
    ").select(\n",
    "    pl.col(c) for c in df.columns\n",
    ").collect().get_columns()\n",
    "\n",
    "for c in cs:\n",
    "    print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in df.partition_by(\"a\"):\n",
    "    print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pl.col(c).n_unique() for c in df.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "d = pl.DataFrame(\n",
    "    {\n",
    "        'num': np.random.random(1000),\n",
    "    }\n",
    ")\n",
    "plan = d.lazy().select(\n",
    "    new_col = (pl.col(\"num\") - 2.55678623)/1.11111111\n",
    ")\n",
    "plan.write_json(\"test.json\")\n",
    "d2 = d.clone()\n",
    "f = open(\"test.json\", \"r\")\n",
    "json_str = f.read()\n",
    "f.close()\n",
    "test = d2.lazy().from_json(json_str).rename({\"new_col\":\"new_col2\"})\n",
    "\n",
    "different_values = plan.collect()[\"new_col\"] != test.collect()[\"new_col2\"]\n",
    "print(different_values.sum())\n",
    "combined = pl.concat([plan.collect(), test.collect()], how=\"horizontal\")\n",
    "data = combined.filter(pl.col(\"new_col\") != pl.col(\"new_col2\"))\n",
    "print(data[1, 0])\n",
    "print(data[1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.select(pl.col(\"bools\").sum() / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.lazy().select(pl.col(\"num\").mean()).collect().to_numpy()[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.select(\n",
    "    pl.col(\"events\").list.unique().list.lengths()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_x, orig_y = make_classification(n_samples = 300_000, n_features = 50, n_informative = 25, n_redundant = 25)\n",
    "df = pl.from_numpy(orig_x).insert_at_idx(0, pl.Series(\"target\", orig_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns\n",
    "features.remove(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.select(features)\n",
    "v = pl.Series([2]*len(features))\n",
    "\n",
    "print(x.shape)\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x.select(\n",
    "    pl.col(c) * v[i] for i, c in enumerate(x.columns)\n",
    ").fold(lambda s1, s2: s1 + s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x.select(\n",
    "    sum(pl.col(c) * v[i] for i, c in enumerate(x.columns))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pl.Series([2]*200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(df:pl.DataFrame, features:list[str], target:str):\n",
    "    \n",
    "    x = df.select(features)\n",
    "    y = df.select(target)\n",
    "\n",
    "    weights = pl.Series([1]*len(features))\n",
    "    const = 0.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from dsds.prescreen import describe_str\n",
    "from dsds.transform import ScalingStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"../data/advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_str(df, words_to_count=[\"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
