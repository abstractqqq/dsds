{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import polars as pl \n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "The system cannot find the file specified. (os error 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpolars\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m \n\u001b[1;32m----> 4\u001b[0m df \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mscan_csv(\u001b[39m\"\u001b[39;49m\u001b[39m../data/test.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Define polars custom functions to apply\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_position_column\u001b[39m(df:pl\u001b[39m.\u001b[39mLazyFrame):\n",
      "File \u001b[1;32mc:\\Users\\qtren\\miniconda3\\envs\\my_py11\\Lib\\site-packages\\polars\\io\\csv\\functions.py:875\u001b[0m, in \u001b[0;36mscan_csv\u001b[1;34m(source, has_header, separator, comment_char, quote_char, skip_rows, dtypes, null_values, missing_utf8_is_empty_string, ignore_errors, cache, with_column_names, infer_schema_length, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_count_name, row_count_offset, try_parse_dates, eol_char, new_columns)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(source, (\u001b[39mstr\u001b[39m, Path)):\n\u001b[0;32m    873\u001b[0m     source \u001b[39m=\u001b[39m normalise_filepath(source)\n\u001b[1;32m--> 875\u001b[0m \u001b[39mreturn\u001b[39;00m pl\u001b[39m.\u001b[39;49mLazyFrame\u001b[39m.\u001b[39;49m_scan_csv(\n\u001b[0;32m    876\u001b[0m     source,\n\u001b[0;32m    877\u001b[0m     has_header\u001b[39m=\u001b[39;49mhas_header,\n\u001b[0;32m    878\u001b[0m     separator\u001b[39m=\u001b[39;49mseparator,\n\u001b[0;32m    879\u001b[0m     comment_char\u001b[39m=\u001b[39;49mcomment_char,\n\u001b[0;32m    880\u001b[0m     quote_char\u001b[39m=\u001b[39;49mquote_char,\n\u001b[0;32m    881\u001b[0m     skip_rows\u001b[39m=\u001b[39;49mskip_rows,\n\u001b[0;32m    882\u001b[0m     dtypes\u001b[39m=\u001b[39;49mdtypes,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    883\u001b[0m     null_values\u001b[39m=\u001b[39;49mnull_values,\n\u001b[0;32m    884\u001b[0m     missing_utf8_is_empty_string\u001b[39m=\u001b[39;49mmissing_utf8_is_empty_string,\n\u001b[0;32m    885\u001b[0m     ignore_errors\u001b[39m=\u001b[39;49mignore_errors,\n\u001b[0;32m    886\u001b[0m     cache\u001b[39m=\u001b[39;49mcache,\n\u001b[0;32m    887\u001b[0m     with_column_names\u001b[39m=\u001b[39;49mwith_column_names,\n\u001b[0;32m    888\u001b[0m     infer_schema_length\u001b[39m=\u001b[39;49minfer_schema_length,\n\u001b[0;32m    889\u001b[0m     n_rows\u001b[39m=\u001b[39;49mn_rows,\n\u001b[0;32m    890\u001b[0m     low_memory\u001b[39m=\u001b[39;49mlow_memory,\n\u001b[0;32m    891\u001b[0m     rechunk\u001b[39m=\u001b[39;49mrechunk,\n\u001b[0;32m    892\u001b[0m     skip_rows_after_header\u001b[39m=\u001b[39;49mskip_rows_after_header,\n\u001b[0;32m    893\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    894\u001b[0m     row_count_name\u001b[39m=\u001b[39;49mrow_count_name,\n\u001b[0;32m    895\u001b[0m     row_count_offset\u001b[39m=\u001b[39;49mrow_count_offset,\n\u001b[0;32m    896\u001b[0m     try_parse_dates\u001b[39m=\u001b[39;49mtry_parse_dates,\n\u001b[0;32m    897\u001b[0m     eol_char\u001b[39m=\u001b[39;49meol_char,\n\u001b[0;32m    898\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\qtren\\miniconda3\\envs\\my_py11\\Lib\\site-packages\\polars\\lazyframe\\frame.py:350\u001b[0m, in \u001b[0;36mLazyFrame._scan_csv\u001b[1;34m(cls, source, has_header, separator, comment_char, quote_char, skip_rows, dtypes, null_values, missing_utf8_is_empty_string, ignore_errors, cache, with_column_names, infer_schema_length, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_count_name, row_count_offset, try_parse_dates, eol_char)\u001b[0m\n\u001b[0;32m    347\u001b[0m processed_null_values \u001b[39m=\u001b[39m _process_null_values(null_values)\n\u001b[0;32m    349\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[1;32m--> 350\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ldf \u001b[39m=\u001b[39m PyLazyFrame\u001b[39m.\u001b[39;49mnew_from_csv(\n\u001b[0;32m    351\u001b[0m     source,\n\u001b[0;32m    352\u001b[0m     separator,\n\u001b[0;32m    353\u001b[0m     has_header,\n\u001b[0;32m    354\u001b[0m     ignore_errors,\n\u001b[0;32m    355\u001b[0m     skip_rows,\n\u001b[0;32m    356\u001b[0m     n_rows,\n\u001b[0;32m    357\u001b[0m     cache,\n\u001b[0;32m    358\u001b[0m     dtype_list,\n\u001b[0;32m    359\u001b[0m     low_memory,\n\u001b[0;32m    360\u001b[0m     comment_char,\n\u001b[0;32m    361\u001b[0m     quote_char,\n\u001b[0;32m    362\u001b[0m     processed_null_values,\n\u001b[0;32m    363\u001b[0m     missing_utf8_is_empty_string,\n\u001b[0;32m    364\u001b[0m     infer_schema_length,\n\u001b[0;32m    365\u001b[0m     with_column_names,\n\u001b[0;32m    366\u001b[0m     rechunk,\n\u001b[0;32m    367\u001b[0m     skip_rows_after_header,\n\u001b[0;32m    368\u001b[0m     encoding,\n\u001b[0;32m    369\u001b[0m     _prepare_row_count_args(row_count_name, row_count_offset),\n\u001b[0;32m    370\u001b[0m     try_parse_dates,\n\u001b[0;32m    371\u001b[0m     eol_char\u001b[39m=\u001b[39;49meol_char,\n\u001b[0;32m    372\u001b[0m )\n\u001b[0;32m    373\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31mOSError\u001b[0m: The system cannot find the file specified. (os error 2)"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import random \n",
    "\n",
    "df = pl.scan_csv(\"../data/test.csv\")\n",
    "    \n",
    "# Define polars custom functions to apply\n",
    "def add_position_column(df:pl.LazyFrame):\n",
    "    df = df.with_columns( \n",
    "        pl.when(pl.col('defensive_skill') > 50).then('CB')\n",
    "        .when(pl.col('offensive_skill') > 50).then('FW')\n",
    "        .otherwise('bench').alias(\"position\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def add_squad_number_column(df:pl.LazyFrame):\n",
    "    df = df.with_columns( \n",
    "        pl.when(pl.col('position') == 'CD').then(pl.lit(random.sample(range(2, 6), 1)[0], dtype=pl.Int8))\n",
    "        .when(pl.col('position') == 'FW').then(pl.lit(random.sample(range(7, 19), 1)[0], dtype=pl.Int8))\n",
    "        .otherwise('-').alias(\"squad_number\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Chain operations together using the pipe function\n",
    "\n",
    "\n",
    "df.pipe(add_position_column)\\\n",
    "    .pipe(add_squad_number_column)\\\n",
    "    .write_json(\"pipe.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"pipe.json\", \"r\")\n",
    "json_str = f.read()\n",
    "f.close()\n",
    "df3 = pl.read_csv(\"../data/test.csv\")\n",
    "df2 = df3.lazy().from_json(json_str)\n",
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = pl.LazyFrame().from_json(json_str)\n",
    "plan.write_json(\"pipe.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df2\u001b[39m.\u001b[39mcollect()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a|b'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"a\",\"b\"]\n",
    "\n",
    "\"|\".join(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test() -> list[str]:\n",
    "    return [\"a\"]\n",
    "\n",
    "test.__annotations__.get(\"return\", \"\") == list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Concatenate\n",
    "\n",
    "tt:Callable[[], list]\n",
    "tt = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect.signature(tt).return_annotation == \"list[str]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\n",
    "    \"g\": list(range(1000))\n",
    "}).lazy()\n",
    "\n",
    "# test = pl.Series(\"x\",[\"a\", \"b\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df = pl.LazyFrame((list(range(1000)), list(i*2 for i in range(1000))), schema=[\"g\", \"g_mapped\"])\n",
    "join_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "df.with_columns(\n",
    "    pl.col(\"g\").map_dict({i:2*i for i in range(1000)})\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "df.join(join_df, on = \"g\").with_columns(\n",
    "    pl.col(\"g_mapped\").alias(\"g\")\n",
    ").drop(columns=[\"g_mapped\"]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.join(join_df, on = \"g\").with_columns(\n",
    "    pl.col(\"g_mapped\").alias(\"g\")\n",
    ").drop(columns=[\"g_mapped\"]).write_json(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"a\": list(range(1000)),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator, Tuple, Any\n",
    "\n",
    "mapping = {i:i for i in range(1000)}\n",
    "test = mapping.copy()\n",
    "cname = \"a\"\n",
    "def create_map_expr(\n",
    "        col_name:str\n",
    "        , gen:Generator[Tuple[str, Any], None, None]\n",
    "        , default:Any = None\n",
    ") -> pl.Expr:\n",
    "\n",
    "    '''\n",
    "        Suppose you have a dictionary like d = {\"a\":1, \"b\":2}. Instead of doing pl.col(\"column\").map_dict(d), you can \n",
    "        do pl.when(pl.col(\"column\") == \"a\").then(1).otherwise(pl.when(pl.col(\"column\") == \"b\").then(2).otherwise(default))\n",
    "        instead. This function generators this expression for you from a generator that yields a key value pair.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        k, v = next(gen)\n",
    "        return pl.when(pl.col(col_name) == k).then(v).otherwise(create_map_expr(col_name, gen))\n",
    "    except:\n",
    "        return pl.lit(default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "df.select(\n",
    "    pl.col(\"a\").map_dict(mapping)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = list(range(1000))\n",
    "expr = create_map_expr(cname, zip(m, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "\n",
    "df.select(\n",
    "    expr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\"a\":[None, 1], \"b\":[1,2]})\n",
    "df2 = pl.DataFrame({\"a\":[None, 1], \"c\":[3,4]})\n",
    "\n",
    "df.join(df2, how=\"left\", on = \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute error, because pl.col(c) returns columns of different len depending on unique values\n",
    "df.select(\n",
    "    pl.col(c).unique().sort() for c in df.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = df.lazy().groupby(1).agg(\n",
    "    pl.col(c).unique().sort() for c in df.columns\n",
    ").select(\n",
    "    pl.col(c) for c in df.columns\n",
    ").collect().get_columns()\n",
    "\n",
    "for c in cs:\n",
    "    print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in df.partition_by(\"a\"):\n",
    "    print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pl.col(c).n_unique() for c in df.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pl.DataFrame(\n",
    "    {\n",
    "        \"id\": [\"a\", \"b\", \"c\", \"d\"],\n",
    "        'num': [1,2,3,4],\n",
    "        \"events\": [[\"e1\", \"e2\"], [\"e1\", \"e2\"], [\"e1\", \"e3\"], [None]],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.lazy().select(pl.col(\"num\").mean()).collect().to_numpy()[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.select(\n",
    "    pl.col(\"events\").list.unique().list.lengths()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_x, orig_y = make_classification(n_samples = 300_000, n_features = 50, n_informative = 25, n_redundant = 25)\n",
    "df = pl.from_numpy(orig_x).insert_at_idx(0, pl.Series(\"target\", orig_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns\n",
    "features.remove(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.select(features)\n",
    "v = pl.Series([2]*len(features))\n",
    "\n",
    "print(x.shape)\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x.select(\n",
    "    pl.col(c) * v[i] for i, c in enumerate(x.columns)\n",
    ").fold(lambda s1, s2: s1 + s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x.select(\n",
    "    sum(pl.col(c) * v[i] for i, c in enumerate(x.columns))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pl.Series([2]*200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(df:pl.DataFrame, features:list[str], target:str):\n",
    "    \n",
    "    x = df.select(features)\n",
    "    y = df.select(target)\n",
    "\n",
    "    weights = pl.Series([1]*len(features))\n",
    "    const = 0.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from dsds.prescreen import describe_str\n",
    "from dsds.transform import ScalingStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"../data/advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_str(df, words_to_count=[\"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
