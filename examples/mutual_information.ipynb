{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from scipy.special import psi\n",
    "from sklearn.datasets import make_classification\n",
    "from typing import Any\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_x, orig_y = make_classification(n_samples = 300_000, n_features = 50, n_informative = 25, n_redundant = 25)\n",
    "df = pl.from_numpy(orig_x).insert_at_idx(0, pl.Series(\"target\", orig_y))\n",
    "target = \"target\"\n",
    "features = df.columns\n",
    "features.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "def estimate_mi_optimized(df:pl.DataFrame, cols:list[str], target:str, k=3, random_state:int=42):\n",
    "\n",
    "    n = len(df)\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    target_col = df.get_column(target).to_numpy().ravel()\n",
    "    unique_targets = np.unique(target_col)\n",
    "    # parts = {t:df.filter((pl.col(target) == t)) for t in df[target].unique()}\n",
    "    # To do: If any part size < k, abort. This gets rid of \"points with unique labels\" issue too.\n",
    "    all_masks = {}\n",
    "    for t in unique_targets:\n",
    "        all_masks[t] = target_col == t\n",
    "        if len(df.filter(pl.col(target) == t)) <= k:\n",
    "            raise ValueError(f\"The target class {t} must have more than {k} values in the dataset.\")        \n",
    "\n",
    "    estimates = []\n",
    "    psi_n_and_k = psi(n) + psi(k)\n",
    "    for col in cols:\n",
    "        c = df.get_column(col).to_numpy().reshape(-1,1)\n",
    "        c = c + (1e-10 * np.mean(c) * rng.standard_normal(size=c.shape))\n",
    "        radius = np.empty(n)\n",
    "        label_counts = np.empty(n)\n",
    "        for t in unique_targets:\n",
    "            mask = all_masks[t]\n",
    "            c_masked = c[mask]\n",
    "            kd1 = KDTree(data=c_masked)\n",
    "            # dd = distances from the points the the k nearest points. +1 because this starts from 0. It is 1 off from sklearn's kdtree.\n",
    "            dd, _ = kd1.query(c_masked, k = k + 1, workers=-1)\n",
    "            radius[mask] = np.nextafter(dd[:, -1], 0)\n",
    "            label_counts[mask] = np.sum(mask)\n",
    "\n",
    "        kd2 = KDTree(data=c) \n",
    "        m_all = kd2.query_ball_point(c, r = radius, return_length=True, workers=-1)\n",
    "        estimates.append(\n",
    "            max(0, psi_n_and_k - np.mean(psi(label_counts) + psi(m_all)))\n",
    "        )\n",
    "\n",
    "    output = pl.from_records([cols, estimates], schema=[\"feature\", \"estimated_mi\"])\n",
    "    return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = perf_counter()\n",
    "output = estimate_mi_optimized(df, target=target, cols=features).sort(\"estimated_mi\",  descending=True)\n",
    "end = perf_counter()\n",
    "print(f\"Spent {end-start:.2f}s.\")\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def estimate_mi_sklearn(df:pl.DataFrame, cols:list[str], target:str, k=3, random_state:int=42):\n",
    "    mi_estimates = mutual_info_classif(df[cols], df[target]\n",
    "                        , n_neighbors=k, random_state=random_state, discrete_features=False)\n",
    "\n",
    "    return pl.from_records([cols, mi_estimates], schema=[\"feature\", \"estimated_mi\"]).sort(\"estimated_mi\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = perf_counter()\n",
    "output = estimate_mi_sklearn(df, target=target, cols=features).sort(\"estimated_mi\",  descending=True)\n",
    "end = perf_counter()\n",
    "print(f\"Spent {end-start:.2f}s.\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from dsds.fs import mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info(df, conti_cols=features, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
