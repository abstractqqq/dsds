{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from time import perf_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_x, orig_y = make_classification(n_samples = 100_000, n_features = 100, n_informative = 60, n_redundant = 40)\n",
    "# This is a Polars dataframe. This is dsds package's favored dataframe. dsds relies on Polars heavily.\n",
    "# You must turn other dataframe formats into Polars for dsds to work.\n",
    "df = pl.from_numpy(orig_x).insert_at_idx(0, pl.Series(\"target\", orig_y)) \n",
    "# Turn it into Pandas.\n",
    "df_pd = df.to_pandas()\n",
    "target = \"target\"\n",
    "features = df.columns\n",
    "features.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 101)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th><th>column_0</th><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th><th>column_8</th><th>column_9</th><th>column_10</th><th>column_11</th><th>column_12</th><th>column_13</th><th>column_14</th><th>column_15</th><th>column_16</th><th>column_17</th><th>column_18</th><th>column_19</th><th>column_20</th><th>column_21</th><th>column_22</th><th>column_23</th><th>column_24</th><th>column_25</th><th>column_26</th><th>column_27</th><th>column_28</th><th>column_29</th><th>column_30</th><th>column_31</th><th>column_32</th><th>column_33</th><th>column_34</th><th>column_35</th><th>&hellip;</th><th>column_63</th><th>column_64</th><th>column_65</th><th>column_66</th><th>column_67</th><th>column_68</th><th>column_69</th><th>column_70</th><th>column_71</th><th>column_72</th><th>column_73</th><th>column_74</th><th>column_75</th><th>column_76</th><th>column_77</th><th>column_78</th><th>column_79</th><th>column_80</th><th>column_81</th><th>column_82</th><th>column_83</th><th>column_84</th><th>column_85</th><th>column_86</th><th>column_87</th><th>column_88</th><th>column_89</th><th>column_90</th><th>column_91</th><th>column_92</th><th>column_93</th><th>column_94</th><th>column_95</th><th>column_96</th><th>column_97</th><th>column_98</th><th>column_99</th></tr><tr><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>5.986819</td><td>0.546596</td><td>1.648701</td><td>3.997167</td><td>7.458675</td><td>-10.106747</td><td>-1.624208</td><td>1.137966</td><td>-1.158476</td><td>2.997509</td><td>4.086229</td><td>-1.26675</td><td>-1.777032</td><td>-28.261351</td><td>30.073757</td><td>25.743075</td><td>-6.093473</td><td>0.064229</td><td>-0.318723</td><td>13.616268</td><td>-6.754464</td><td>-1.317529</td><td>3.310598</td><td>0.592153</td><td>0.423041</td><td>-2.356806</td><td>-33.492711</td><td>-2.162182</td><td>-1.672547</td><td>-0.452053</td><td>7.331551</td><td>19.98831</td><td>-3.633311</td><td>5.3967</td><td>15.262042</td><td>6.747133</td><td>&hellip;</td><td>-0.355568</td><td>-20.007311</td><td>0.619315</td><td>-7.78998</td><td>2.763447</td><td>3.997654</td><td>-0.956993</td><td>48.206937</td><td>3.92971</td><td>0.351252</td><td>-2.083404</td><td>-1.703559</td><td>4.076559</td><td>-2.069447</td><td>0.184148</td><td>0.450871</td><td>-5.936437</td><td>5.175711</td><td>-4.965513</td><td>-2.766612</td><td>-5.352892</td><td>15.179981</td><td>31.906209</td><td>0.483883</td><td>14.708496</td><td>-21.290712</td><td>-1.581163</td><td>-1.675474</td><td>4.842297</td><td>-12.407528</td><td>-2.956569</td><td>2.583529</td><td>-13.347925</td><td>17.690473</td><td>10.234511</td><td>6.890357</td><td>18.68473</td></tr><tr><td>1</td><td>4.147852</td><td>-10.166797</td><td>2.42494</td><td>-8.280883</td><td>0.694632</td><td>2.354545</td><td>-3.867516</td><td>4.401109</td><td>-8.34216</td><td>1.981496</td><td>-8.092609</td><td>2.311992</td><td>-1.925248</td><td>-53.891539</td><td>-12.550992</td><td>-15.345019</td><td>16.917992</td><td>7.096581</td><td>1.1973</td><td>-20.604139</td><td>-6.664765</td><td>-8.888499</td><td>-2.397954</td><td>4.17647</td><td>21.591129</td><td>-5.005256</td><td>-16.221116</td><td>0.459742</td><td>-0.690709</td><td>-0.269417</td><td>-3.044781</td><td>-25.934654</td><td>-0.610498</td><td>-7.233787</td><td>2.394237</td><td>1.998173</td><td>&hellip;</td><td>2.411827</td><td>10.014729</td><td>-5.52803</td><td>-32.598132</td><td>1.486695</td><td>33.294182</td><td>-4.239926</td><td>2.168909</td><td>-5.448569</td><td>7.679037</td><td>0.707344</td><td>-58.678729</td><td>12.111013</td><td>-13.529477</td><td>3.332116</td><td>0.214316</td><td>-0.885962</td><td>-0.134195</td><td>2.699072</td><td>3.252907</td><td>-29.258296</td><td>1.955882</td><td>54.63539</td><td>9.576148</td><td>3.437032</td><td>-0.501529</td><td>-18.291438</td><td>3.040755</td><td>-3.619622</td><td>5.837794</td><td>0.914736</td><td>-3.164613</td><td>8.694552</td><td>40.241724</td><td>-50.204775</td><td>0.888179</td><td>18.313636</td></tr><tr><td>1</td><td>-1.065503</td><td>-3.389961</td><td>-3.420557</td><td>0.969395</td><td>-0.685428</td><td>1.423848</td><td>-0.437088</td><td>-1.246797</td><td>10.319519</td><td>-3.428728</td><td>2.236986</td><td>-0.177996</td><td>-34.727854</td><td>6.973909</td><td>19.521618</td><td>0.671872</td><td>-30.380552</td><td>2.287781</td><td>7.248455</td><td>34.126478</td><td>-10.555192</td><td>1.861879</td><td>-0.576845</td><td>-5.463621</td><td>0.438259</td><td>-1.040704</td><td>6.654079</td><td>2.672152</td><td>2.830621</td><td>2.811892</td><td>-13.247055</td><td>-28.399984</td><td>-7.399742</td><td>0.051395</td><td>10.644678</td><td>-1.586821</td><td>&hellip;</td><td>-1.996005</td><td>13.915336</td><td>1.952686</td><td>6.921012</td><td>-0.136747</td><td>11.963771</td><td>1.013418</td><td>-9.571991</td><td>0.928034</td><td>-5.626219</td><td>7.528923</td><td>46.134983</td><td>15.170741</td><td>3.778057</td><td>8.584322</td><td>-7.137716</td><td>8.735825</td><td>2.60461</td><td>3.386294</td><td>-1.134204</td><td>-18.723313</td><td>2.136473</td><td>-20.611045</td><td>-0.88672</td><td>10.00448</td><td>51.431367</td><td>-6.196474</td><td>-1.776183</td><td>2.446435</td><td>-27.402815</td><td>3.859099</td><td>0.076166</td><td>2.663502</td><td>-15.066364</td><td>14.214258</td><td>-4.997656</td><td>-10.976358</td></tr><tr><td>1</td><td>-6.161803</td><td>-0.062358</td><td>0.309762</td><td>-1.479081</td><td>3.194638</td><td>0.56878</td><td>1.58343</td><td>7.261861</td><td>-0.902904</td><td>2.114949</td><td>-7.247418</td><td>2.592263</td><td>33.789852</td><td>-1.67435</td><td>-7.637536</td><td>9.335591</td><td>-21.62965</td><td>0.534352</td><td>4.499181</td><td>-11.933576</td><td>-3.985087</td><td>-3.348656</td><td>-7.057779</td><td>4.619226</td><td>-41.132171</td><td>1.753467</td><td>-1.937991</td><td>-9.15416</td><td>3.534515</td><td>0.43227</td><td>1.178357</td><td>-6.930231</td><td>5.532963</td><td>24.726412</td><td>-28.003835</td><td>-0.174675</td><td>&hellip;</td><td>2.075758</td><td>6.714418</td><td>6.689934</td><td>7.808172</td><td>1.958908</td><td>6.354117</td><td>-1.641288</td><td>26.176752</td><td>2.580099</td><td>0.569722</td><td>-6.041869</td><td>10.712468</td><td>-7.501954</td><td>0.153475</td><td>6.695536</td><td>-4.308605</td><td>-9.99083</td><td>-1.252156</td><td>-3.926162</td><td>10.932434</td><td>-3.135962</td><td>-32.845303</td><td>15.726288</td><td>-2.7377</td><td>-28.695589</td><td>28.466205</td><td>-8.143614</td><td>-4.502438</td><td>0.367855</td><td>-5.163827</td><td>-3.900286</td><td>3.373313</td><td>-11.310146</td><td>2.678528</td><td>-7.299003</td><td>-5.557134</td><td>-21.532237</td></tr><tr><td>0</td><td>-9.346525</td><td>-1.482052</td><td>-3.0823</td><td>4.833217</td><td>4.801851</td><td>3.362576</td><td>-0.04595</td><td>-6.515114</td><td>-0.946761</td><td>-8.299702</td><td>8.758147</td><td>-7.065284</td><td>-19.829434</td><td>11.72991</td><td>-15.416421</td><td>17.954306</td><td>-16.494773</td><td>-1.444415</td><td>4.670239</td><td>-0.473956</td><td>3.104503</td><td>1.078318</td><td>-2.020297</td><td>0.557246</td><td>-37.436009</td><td>-5.833064</td><td>13.483283</td><td>-1.901863</td><td>0.044479</td><td>7.748179</td><td>-6.716373</td><td>-1.218635</td><td>-7.470528</td><td>8.093139</td><td>36.106036</td><td>1.36148</td><td>&hellip;</td><td>-1.859693</td><td>21.998676</td><td>9.837191</td><td>-3.402064</td><td>2.081736</td><td>-26.483819</td><td>-2.293431</td><td>7.786315</td><td>0.620095</td><td>0.014286</td><td>-3.81728</td><td>21.605818</td><td>-2.640408</td><td>1.411127</td><td>-1.288832</td><td>0.95443</td><td>-1.590785</td><td>-3.234581</td><td>-2.168327</td><td>-0.689682</td><td>6.424369</td><td>-22.005775</td><td>-39.736955</td><td>4.62584</td><td>-26.503795</td><td>-6.597121</td><td>-33.573717</td><td>-6.494197</td><td>-3.668589</td><td>6.325084</td><td>1.606812</td><td>3.314172</td><td>17.470099</td><td>-26.354451</td><td>-11.840262</td><td>-1.798413</td><td>-6.893892</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 101)\n",
       "┌────────┬───────────┬────────────┬───────────┬───┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ target ┆ column_0  ┆ column_1   ┆ column_2  ┆ … ┆ column_96  ┆ column_97 ┆ column_98 ┆ column_99 │\n",
       "│ ---    ┆ ---       ┆ ---        ┆ ---       ┆   ┆ ---        ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ i32    ┆ f64       ┆ f64        ┆ f64       ┆   ┆ f64        ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════╪═══════════╪════════════╪═══════════╪═══╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1      ┆ 5.986819  ┆ 0.546596   ┆ 1.648701  ┆ … ┆ 17.690473  ┆ 10.234511 ┆ 6.890357  ┆ 18.68473  │\n",
       "│ 1      ┆ 4.147852  ┆ -10.166797 ┆ 2.42494   ┆ … ┆ 40.241724  ┆ -50.20477 ┆ 0.888179  ┆ 18.313636 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆ 5         ┆           ┆           │\n",
       "│ 1      ┆ -1.065503 ┆ -3.389961  ┆ -3.420557 ┆ … ┆ -15.066364 ┆ 14.214258 ┆ -4.997656 ┆ -10.97635 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆           ┆           ┆ 8         │\n",
       "│ 1      ┆ -6.161803 ┆ -0.062358  ┆ 0.309762  ┆ … ┆ 2.678528   ┆ -7.299003 ┆ -5.557134 ┆ -21.53223 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆           ┆           ┆ 7         │\n",
       "│ 0      ┆ -9.346525 ┆ -1.482052  ┆ -3.0823   ┆ … ┆ -26.354451 ┆ -11.84026 ┆ -1.798413 ┆ -6.893892 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆ 2         ┆           ┆           │\n",
       "└────────┴───────────┴────────────┴───────────┴───┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons\n",
    "\n",
    "This notebook compares results and performance between the dsds package, sklearn and some other packages for feature selection and some other transformations common in the data science pipeline.\n",
    "\n",
    "### Methods Compared:\n",
    "1. Scaling and Imputation\n",
    "2. Fscore\n",
    "3. Mutual Information Score\n",
    "4. MRMR feature selection strategies\n",
    "5. Power Transform\n",
    "\n",
    "You may restart the kernel after each section. But remember to rerun the cells above. If you are concerned about memory usage when running this notebook, go to the end and run the gc cell."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling and Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dsds.transform as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns\n",
    "features.remove(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 101)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th><th>column_0</th><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th><th>column_8</th><th>column_9</th><th>column_10</th><th>column_11</th><th>column_12</th><th>column_13</th><th>column_14</th><th>column_15</th><th>column_16</th><th>column_17</th><th>column_18</th><th>column_19</th><th>column_20</th><th>column_21</th><th>column_22</th><th>column_23</th><th>column_24</th><th>column_25</th><th>column_26</th><th>column_27</th><th>column_28</th><th>column_29</th><th>column_30</th><th>column_31</th><th>column_32</th><th>column_33</th><th>column_34</th><th>column_35</th><th>&hellip;</th><th>column_63</th><th>column_64</th><th>column_65</th><th>column_66</th><th>column_67</th><th>column_68</th><th>column_69</th><th>column_70</th><th>column_71</th><th>column_72</th><th>column_73</th><th>column_74</th><th>column_75</th><th>column_76</th><th>column_77</th><th>column_78</th><th>column_79</th><th>column_80</th><th>column_81</th><th>column_82</th><th>column_83</th><th>column_84</th><th>column_85</th><th>column_86</th><th>column_87</th><th>column_88</th><th>column_89</th><th>column_90</th><th>column_91</th><th>column_92</th><th>column_93</th><th>column_94</th><th>column_95</th><th>column_96</th><th>column_97</th><th>column_98</th><th>column_99</th></tr><tr><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>5.986819</td><td>0.546596</td><td>1.648701</td><td>3.997167</td><td>7.458675</td><td>-10.106747</td><td>-1.624208</td><td>1.137966</td><td>-1.158476</td><td>2.997509</td><td>4.086229</td><td>-1.26675</td><td>-1.777032</td><td>-28.261351</td><td>30.073757</td><td>25.743075</td><td>-6.093473</td><td>0.064229</td><td>-0.318723</td><td>13.616268</td><td>-6.754464</td><td>-1.317529</td><td>3.310598</td><td>0.592153</td><td>0.423041</td><td>-2.356806</td><td>-33.492711</td><td>-2.162182</td><td>-1.672547</td><td>-0.452053</td><td>7.331551</td><td>19.98831</td><td>-3.633311</td><td>5.3967</td><td>15.262042</td><td>6.747133</td><td>&hellip;</td><td>-0.355568</td><td>-20.007311</td><td>0.619315</td><td>-7.78998</td><td>2.763447</td><td>3.997654</td><td>-0.956993</td><td>48.206937</td><td>3.92971</td><td>0.351252</td><td>-2.083404</td><td>-1.703559</td><td>4.076559</td><td>-2.069447</td><td>0.184148</td><td>0.450871</td><td>-5.936437</td><td>5.175711</td><td>-4.965513</td><td>-2.766612</td><td>-5.352892</td><td>15.179981</td><td>31.906209</td><td>0.483883</td><td>14.708496</td><td>-21.290712</td><td>-1.581163</td><td>-1.675474</td><td>4.842297</td><td>-12.407528</td><td>-2.956569</td><td>2.583529</td><td>-13.347925</td><td>17.690473</td><td>10.234511</td><td>6.890357</td><td>18.68473</td></tr><tr><td>1</td><td>4.147852</td><td>-10.166797</td><td>2.42494</td><td>-8.280883</td><td>0.694632</td><td>2.354545</td><td>-3.867516</td><td>4.401109</td><td>-8.34216</td><td>1.981496</td><td>-8.092609</td><td>2.311992</td><td>-1.925248</td><td>-53.891539</td><td>-12.550992</td><td>-15.345019</td><td>16.917992</td><td>7.096581</td><td>1.1973</td><td>-20.604139</td><td>-6.664765</td><td>-8.888499</td><td>-2.397954</td><td>4.17647</td><td>21.591129</td><td>-5.005256</td><td>-16.221116</td><td>0.459742</td><td>-0.690709</td><td>-0.269417</td><td>-3.044781</td><td>-25.934654</td><td>-0.610498</td><td>-7.233787</td><td>2.394237</td><td>1.998173</td><td>&hellip;</td><td>2.411827</td><td>10.014729</td><td>-5.52803</td><td>-32.598132</td><td>1.486695</td><td>33.294182</td><td>-4.239926</td><td>2.168909</td><td>-5.448569</td><td>7.679037</td><td>0.707344</td><td>-58.678729</td><td>12.111013</td><td>-13.529477</td><td>3.332116</td><td>0.214316</td><td>-0.885962</td><td>-0.134195</td><td>2.699072</td><td>3.252907</td><td>-29.258296</td><td>1.955882</td><td>54.63539</td><td>9.576148</td><td>3.437032</td><td>-0.501529</td><td>-18.291438</td><td>3.040755</td><td>-3.619622</td><td>5.837794</td><td>0.914736</td><td>-3.164613</td><td>8.694552</td><td>40.241724</td><td>-50.204775</td><td>0.888179</td><td>18.313636</td></tr><tr><td>1</td><td>-1.065503</td><td>-3.389961</td><td>-3.420557</td><td>0.969395</td><td>-0.685428</td><td>1.423848</td><td>-0.437088</td><td>-1.246797</td><td>10.319519</td><td>-3.428728</td><td>2.236986</td><td>-0.177996</td><td>-34.727854</td><td>6.973909</td><td>19.521618</td><td>0.671872</td><td>-30.380552</td><td>2.287781</td><td>7.248455</td><td>34.126478</td><td>-10.555192</td><td>1.861879</td><td>-0.576845</td><td>-5.463621</td><td>0.438259</td><td>-1.040704</td><td>6.654079</td><td>2.672152</td><td>2.830621</td><td>2.811892</td><td>-13.247055</td><td>-28.399984</td><td>-7.399742</td><td>0.051395</td><td>10.644678</td><td>-1.586821</td><td>&hellip;</td><td>-1.996005</td><td>13.915336</td><td>1.952686</td><td>6.921012</td><td>-0.136747</td><td>11.963771</td><td>1.013418</td><td>-9.571991</td><td>0.928034</td><td>-5.626219</td><td>7.528923</td><td>46.134983</td><td>15.170741</td><td>3.778057</td><td>8.584322</td><td>-7.137716</td><td>8.735825</td><td>2.60461</td><td>3.386294</td><td>-1.134204</td><td>-18.723313</td><td>2.136473</td><td>-20.611045</td><td>-0.88672</td><td>10.00448</td><td>51.431367</td><td>-6.196474</td><td>-1.776183</td><td>2.446435</td><td>-27.402815</td><td>3.859099</td><td>0.076166</td><td>2.663502</td><td>-15.066364</td><td>14.214258</td><td>-4.997656</td><td>-10.976358</td></tr><tr><td>1</td><td>-6.161803</td><td>-0.062358</td><td>0.309762</td><td>-1.479081</td><td>3.194638</td><td>0.56878</td><td>1.58343</td><td>7.261861</td><td>-0.902904</td><td>2.114949</td><td>-7.247418</td><td>2.592263</td><td>33.789852</td><td>-1.67435</td><td>-7.637536</td><td>9.335591</td><td>-21.62965</td><td>0.534352</td><td>4.499181</td><td>-11.933576</td><td>-3.985087</td><td>-3.348656</td><td>-7.057779</td><td>4.619226</td><td>-41.132171</td><td>1.753467</td><td>-1.937991</td><td>-9.15416</td><td>3.534515</td><td>0.43227</td><td>1.178357</td><td>-6.930231</td><td>5.532963</td><td>24.726412</td><td>-28.003835</td><td>-0.174675</td><td>&hellip;</td><td>2.075758</td><td>6.714418</td><td>6.689934</td><td>7.808172</td><td>1.958908</td><td>6.354117</td><td>-1.641288</td><td>26.176752</td><td>2.580099</td><td>0.569722</td><td>-6.041869</td><td>10.712468</td><td>-7.501954</td><td>0.153475</td><td>6.695536</td><td>-4.308605</td><td>-9.99083</td><td>-1.252156</td><td>-3.926162</td><td>10.932434</td><td>-3.135962</td><td>-32.845303</td><td>15.726288</td><td>-2.7377</td><td>-28.695589</td><td>28.466205</td><td>-8.143614</td><td>-4.502438</td><td>0.367855</td><td>-5.163827</td><td>-3.900286</td><td>3.373313</td><td>-11.310146</td><td>2.678528</td><td>-7.299003</td><td>-5.557134</td><td>-21.532237</td></tr><tr><td>0</td><td>-9.346525</td><td>-1.482052</td><td>-3.0823</td><td>4.833217</td><td>4.801851</td><td>3.362576</td><td>-0.04595</td><td>-6.515114</td><td>-0.946761</td><td>-8.299702</td><td>8.758147</td><td>-7.065284</td><td>-19.829434</td><td>11.72991</td><td>-15.416421</td><td>17.954306</td><td>-16.494773</td><td>-1.444415</td><td>4.670239</td><td>-0.473956</td><td>3.104503</td><td>1.078318</td><td>-2.020297</td><td>0.557246</td><td>-37.436009</td><td>-5.833064</td><td>13.483283</td><td>-1.901863</td><td>0.044479</td><td>7.748179</td><td>-6.716373</td><td>-1.218635</td><td>-7.470528</td><td>8.093139</td><td>36.106036</td><td>1.36148</td><td>&hellip;</td><td>-1.859693</td><td>21.998676</td><td>9.837191</td><td>-3.402064</td><td>2.081736</td><td>-26.483819</td><td>-2.293431</td><td>7.786315</td><td>0.620095</td><td>0.014286</td><td>-3.81728</td><td>21.605818</td><td>-2.640408</td><td>1.411127</td><td>-1.288832</td><td>0.95443</td><td>-1.590785</td><td>-3.234581</td><td>-2.168327</td><td>-0.689682</td><td>6.424369</td><td>-22.005775</td><td>-39.736955</td><td>4.62584</td><td>-26.503795</td><td>-6.597121</td><td>-33.573717</td><td>-6.494197</td><td>-3.668589</td><td>6.325084</td><td>1.606812</td><td>3.314172</td><td>17.470099</td><td>-26.354451</td><td>-11.840262</td><td>-1.798413</td><td>-6.893892</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 101)\n",
       "┌────────┬───────────┬────────────┬───────────┬───┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ target ┆ column_0  ┆ column_1   ┆ column_2  ┆ … ┆ column_96  ┆ column_97 ┆ column_98 ┆ column_99 │\n",
       "│ ---    ┆ ---       ┆ ---        ┆ ---       ┆   ┆ ---        ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ i32    ┆ f64       ┆ f64        ┆ f64       ┆   ┆ f64        ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════╪═══════════╪════════════╪═══════════╪═══╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1      ┆ 5.986819  ┆ 0.546596   ┆ 1.648701  ┆ … ┆ 17.690473  ┆ 10.234511 ┆ 6.890357  ┆ 18.68473  │\n",
       "│ 1      ┆ 4.147852  ┆ -10.166797 ┆ 2.42494   ┆ … ┆ 40.241724  ┆ -50.20477 ┆ 0.888179  ┆ 18.313636 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆ 5         ┆           ┆           │\n",
       "│ 1      ┆ -1.065503 ┆ -3.389961  ┆ -3.420557 ┆ … ┆ -15.066364 ┆ 14.214258 ┆ -4.997656 ┆ -10.97635 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆           ┆           ┆ 8         │\n",
       "│ 1      ┆ -6.161803 ┆ -0.062358  ┆ 0.309762  ┆ … ┆ 2.678528   ┆ -7.299003 ┆ -5.557134 ┆ -21.53223 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆           ┆           ┆ 7         │\n",
       "│ 0      ┆ -9.346525 ┆ -1.482052  ┆ -3.0823   ┆ … ┆ -26.354451 ┆ -11.84026 ┆ -1.798413 ┆ -6.893892 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆ 2         ┆           ┆           │\n",
       "└────────┴───────────┴────────────┴───────────┴───┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>column_0</th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_6</th>\n",
       "      <th>column_7</th>\n",
       "      <th>column_8</th>\n",
       "      <th>...</th>\n",
       "      <th>column_90</th>\n",
       "      <th>column_91</th>\n",
       "      <th>column_92</th>\n",
       "      <th>column_93</th>\n",
       "      <th>column_94</th>\n",
       "      <th>column_95</th>\n",
       "      <th>column_96</th>\n",
       "      <th>column_97</th>\n",
       "      <th>column_98</th>\n",
       "      <th>column_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.986819</td>\n",
       "      <td>0.546596</td>\n",
       "      <td>1.648701</td>\n",
       "      <td>3.997167</td>\n",
       "      <td>7.458675</td>\n",
       "      <td>-10.106747</td>\n",
       "      <td>-1.624208</td>\n",
       "      <td>1.137966</td>\n",
       "      <td>-1.158476</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.675474</td>\n",
       "      <td>4.842297</td>\n",
       "      <td>-12.407528</td>\n",
       "      <td>-2.956569</td>\n",
       "      <td>2.583529</td>\n",
       "      <td>-13.347925</td>\n",
       "      <td>17.690473</td>\n",
       "      <td>10.234511</td>\n",
       "      <td>6.890357</td>\n",
       "      <td>18.684730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.147852</td>\n",
       "      <td>-10.166797</td>\n",
       "      <td>2.424940</td>\n",
       "      <td>-8.280883</td>\n",
       "      <td>0.694632</td>\n",
       "      <td>2.354545</td>\n",
       "      <td>-3.867516</td>\n",
       "      <td>4.401109</td>\n",
       "      <td>-8.342160</td>\n",
       "      <td>...</td>\n",
       "      <td>3.040755</td>\n",
       "      <td>-3.619622</td>\n",
       "      <td>5.837794</td>\n",
       "      <td>0.914736</td>\n",
       "      <td>-3.164613</td>\n",
       "      <td>8.694552</td>\n",
       "      <td>40.241724</td>\n",
       "      <td>-50.204775</td>\n",
       "      <td>0.888179</td>\n",
       "      <td>18.313636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.065503</td>\n",
       "      <td>-3.389961</td>\n",
       "      <td>-3.420557</td>\n",
       "      <td>0.969395</td>\n",
       "      <td>-0.685428</td>\n",
       "      <td>1.423848</td>\n",
       "      <td>-0.437088</td>\n",
       "      <td>-1.246797</td>\n",
       "      <td>10.319519</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.776183</td>\n",
       "      <td>2.446435</td>\n",
       "      <td>-27.402815</td>\n",
       "      <td>3.859099</td>\n",
       "      <td>0.076166</td>\n",
       "      <td>2.663502</td>\n",
       "      <td>-15.066364</td>\n",
       "      <td>14.214258</td>\n",
       "      <td>-4.997656</td>\n",
       "      <td>-10.976358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-6.161803</td>\n",
       "      <td>-0.062358</td>\n",
       "      <td>0.309762</td>\n",
       "      <td>-1.479081</td>\n",
       "      <td>3.194638</td>\n",
       "      <td>0.568780</td>\n",
       "      <td>1.583430</td>\n",
       "      <td>7.261861</td>\n",
       "      <td>-0.902904</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.502438</td>\n",
       "      <td>0.367855</td>\n",
       "      <td>-5.163827</td>\n",
       "      <td>-3.900286</td>\n",
       "      <td>3.373313</td>\n",
       "      <td>-11.310146</td>\n",
       "      <td>2.678528</td>\n",
       "      <td>-7.299003</td>\n",
       "      <td>-5.557134</td>\n",
       "      <td>-21.532237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.346525</td>\n",
       "      <td>-1.482052</td>\n",
       "      <td>-3.082300</td>\n",
       "      <td>4.833217</td>\n",
       "      <td>4.801851</td>\n",
       "      <td>3.362576</td>\n",
       "      <td>-0.045950</td>\n",
       "      <td>-6.515114</td>\n",
       "      <td>-0.946761</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.494197</td>\n",
       "      <td>-3.668589</td>\n",
       "      <td>6.325084</td>\n",
       "      <td>1.606812</td>\n",
       "      <td>3.314172</td>\n",
       "      <td>17.470099</td>\n",
       "      <td>-26.354451</td>\n",
       "      <td>-11.840262</td>\n",
       "      <td>-1.798413</td>\n",
       "      <td>-6.893892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  column_0   column_1  column_2  column_3  column_4   column_5   \n",
       "0       1  5.986819   0.546596  1.648701  3.997167  7.458675 -10.106747  \\\n",
       "1       1  4.147852 -10.166797  2.424940 -8.280883  0.694632   2.354545   \n",
       "2       1 -1.065503  -3.389961 -3.420557  0.969395 -0.685428   1.423848   \n",
       "3       1 -6.161803  -0.062358  0.309762 -1.479081  3.194638   0.568780   \n",
       "4       0 -9.346525  -1.482052 -3.082300  4.833217  4.801851   3.362576   \n",
       "\n",
       "   column_6  column_7   column_8  ...  column_90  column_91  column_92   \n",
       "0 -1.624208  1.137966  -1.158476  ...  -1.675474   4.842297 -12.407528  \\\n",
       "1 -3.867516  4.401109  -8.342160  ...   3.040755  -3.619622   5.837794   \n",
       "2 -0.437088 -1.246797  10.319519  ...  -1.776183   2.446435 -27.402815   \n",
       "3  1.583430  7.261861  -0.902904  ...  -4.502438   0.367855  -5.163827   \n",
       "4 -0.045950 -6.515114  -0.946761  ...  -6.494197  -3.668589   6.325084   \n",
       "\n",
       "   column_93  column_94  column_95  column_96  column_97  column_98  column_99  \n",
       "0  -2.956569   2.583529 -13.347925  17.690473  10.234511   6.890357  18.684730  \n",
       "1   0.914736  -3.164613   8.694552  40.241724 -50.204775   0.888179  18.313636  \n",
       "2   3.859099   0.076166   2.663502 -15.066364  14.214258  -4.997656 -10.976358  \n",
       "3  -3.900286   3.373313 -11.310146   2.678528  -7.299003  -5.557134 -21.532237  \n",
       "4   1.606812   3.314172  17.470099 -26.354451 -11.840262  -1.798413  -6.893892  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 101)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th><th>column_0</th><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th><th>column_8</th><th>column_9</th><th>column_10</th><th>column_11</th><th>column_12</th><th>column_13</th><th>column_14</th><th>column_15</th><th>column_16</th><th>column_17</th><th>column_18</th><th>column_19</th><th>column_20</th><th>column_21</th><th>column_22</th><th>column_23</th><th>column_24</th><th>column_25</th><th>column_26</th><th>column_27</th><th>column_28</th><th>column_29</th><th>column_30</th><th>column_31</th><th>column_32</th><th>column_33</th><th>column_34</th><th>column_35</th><th>&hellip;</th><th>column_63</th><th>column_64</th><th>column_65</th><th>column_66</th><th>column_67</th><th>column_68</th><th>column_69</th><th>column_70</th><th>column_71</th><th>column_72</th><th>column_73</th><th>column_74</th><th>column_75</th><th>column_76</th><th>column_77</th><th>column_78</th><th>column_79</th><th>column_80</th><th>column_81</th><th>column_82</th><th>column_83</th><th>column_84</th><th>column_85</th><th>column_86</th><th>column_87</th><th>column_88</th><th>column_89</th><th>column_90</th><th>column_91</th><th>column_92</th><th>column_93</th><th>column_94</th><th>column_95</th><th>column_96</th><th>column_97</th><th>column_98</th><th>column_99</th></tr><tr><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>1.294905</td><td>0.333453</td><td>0.352402</td><td>1.108324</td><td>1.479123</td><td>-2.306337</td><td>-0.238395</td><td>0.359756</td><td>-0.361</td><td>0.574575</td><td>1.00125</td><td>-0.158437</td><td>-0.120713</td><td>-1.357705</td><td>1.461795</td><td>1.413173</td><td>-0.304733</td><td>0.124442</td><td>-0.287602</td><td>0.615356</td><td>-1.285307</td><td>-0.175165</td><td>0.831514</td><td>0.134627</td><td>0.232212</td><td>-0.64412</td><td>-1.857767</td><td>-0.260619</td><td>-0.260622</td><td>-0.215072</td><td>0.292783</td><td>1.009219</td><td>-0.591925</td><td>0.067739</td><td>0.672425</td><td>1.308126</td><td>&hellip;</td><td>0.036962</td><td>-1.0899</td><td>0.140539</td><td>-0.410279</td><td>0.606058</td><td>0.062623</td><td>-0.103909</td><td>2.61926</td><td>0.658685</td><td>0.311498</td><td>-0.344515</td><td>0.035201</td><td>0.438634</td><td>-0.331842</td><td>0.043715</td><td>0.203418</td><td>-1.385078</td><td>1.372731</td><td>-1.071483</td><td>-0.538954</td><td>-0.070333</td><td>0.617229</td><td>1.579176</td><td>-0.000021</td><td>0.767606</td><td>-1.141811</td><td>0.094667</td><td>-0.252523</td><td>0.879117</td><td>-0.477686</td><td>-0.615769</td><td>0.542548</td><td>-0.605181</td><td>0.756591</td><td>0.69854</td><td>1.585823</td><td>1.030014</td></tr><tr><td>1</td><td>0.898777</td><td>-1.974316</td><td>0.521609</td><td>-1.615605</td><td>-0.066947</td><td>0.541733</td><td>-0.722267</td><td>1.079211</td><td>-1.927822</td><td>0.342838</td><td>-1.675549</td><td>0.611185</td><td>-0.127879</td><td>-2.753463</td><td>-0.660457</td><td>-0.741392</td><td>0.874554</td><td>1.597954</td><td>0.044165</td><td>-1.155583</td><td>-1.265199</td><td>-1.772964</td><td>-0.421137</td><td>0.928928</td><td>1.217453</td><td>-1.244188</td><td>-0.989669</td><td>0.328591</td><td>-0.04569</td><td>-0.173376</td><td>-0.249166</td><td>-1.283373</td><td>0.087737</td><td>-0.494102</td><td>0.059516</td><td>0.227629</td><td>&hellip;</td><td>0.671639</td><td>0.534542</td><td>-1.2431</td><td>-1.853319</td><td>0.328788</td><td>1.458983</td><td>-0.851963</td><td>0.020185</td><td>-1.460235</td><td>1.992302</td><td>0.254837</td><td>-2.688321</td><td>0.909258</td><td>-2.746669</td><td>0.752187</td><td>0.152638</td><td>-0.295849</td><td>0.188946</td><td>0.579498</td><td>0.880194</td><td>-1.269484</td><td>-0.088848</td><td>2.634337</td><td>2.015798</td><td>0.184176</td><td>-0.039079</td><td>-0.803603</td><td>0.776048</td><td>-1.051954</td><td>0.388622</td><td>0.189535</td><td>-0.67145</td><td>0.529248</td><td>1.903783</td><td>-2.402292</td><td>0.298147</td><td>1.011409</td></tr><tr><td>1</td><td>-0.22422</td><td>-0.514519</td><td>-0.752611</td><td>0.436602</td><td>-0.38239</td><td>0.329019</td><td>0.017661</td><td>-0.166034</td><td>2.142446</td><td>-0.891152</td><td>0.594803</td><td>0.075704</td><td>-1.713767</td><td>0.561123</td><td>0.936412</td><td>0.098497</td><td>-1.549393</td><td>0.59035</td><td>1.368402</td><td>1.67678</td><td>-2.137339</td><td>0.495827</td><td>-0.021523</td><td>-1.20736</td><td>0.23292</td><td>-0.345926</td><td>0.160075</td><td>0.825772</td><td>0.725157</td><td>0.530094</td><td>-0.782024</td><td>-1.406449</td><td>-1.438785</td><td>-0.170036</td><td>0.452494</td><td>-0.588039</td><td>&hellip;</td><td>-0.339258</td><td>0.745598</td><td>0.440653</td><td>0.445429</td><td>-0.023772</td><td>0.442312</td><td>0.345071</td><td>-0.642647</td><td>-0.019511</td><td>-1.059579</td><td>1.719866</td><td>2.321975</td><td>1.088484</td><td>0.900328</td><td>1.934233</td><td>-1.425577</td><td>1.779267</td><td>0.799532</td><td>0.727529</td><td>-0.154101</td><td>-0.741024</td><td>-0.079206</td><td>-0.858842</td><td>-0.303893</td><td>0.524118</td><td>2.715627</td><td>-0.153432</td><td>-0.274487</td><td>0.332364</td><td>-1.189679</td><td>0.802017</td><td>0.012997</td><td>0.218857</td><td>-0.909764</td><td>0.90272</td><td>-0.964569</td><td>-0.457124</td></tr><tr><td>1</td><td>-1.322002</td><td>0.202279</td><td>0.060536</td><td>-0.106601</td><td>0.504484</td><td>0.13359</td><td>0.453478</td><td>1.709947</td><td>-0.305258</td><td>0.373277</td><td>-1.489784</td><td>0.671458</td><td>1.598818</td><td>0.09016</td><td>-0.41582</td><td>0.552802</td><td>-1.100928</td><td>0.222948</td><td>0.76675</td><td>-0.706873</td><td>-0.66448</td><td>-0.603819</td><td>-1.44366</td><td>1.027044</td><td>-1.701921</td><td>0.287158</td><td>-0.271776</td><td>-1.831884</td><td>0.879245</td><td>-0.013179</td><td>-0.028594</td><td>-0.334624</td><td>1.469059</td><td>0.927582</td><td>-1.38838</td><td>-0.266744</td><td>&hellip;</td><td>0.594564</td><td>0.355968</td><td>1.506908</td><td>0.497034</td><td>0.431338</td><td>0.174939</td><td>-0.259834</td><td>1.375547</td><td>0.353755</td><td>0.361609</td><td>-1.19465</td><td>0.628711</td><td>-0.239586</td><td>0.136566</td><td>1.509149</td><td>-0.818269</td><td>-2.259483</td><td>-0.060291</td><td>-0.847602</td><td>2.6907</td><td>0.040873</td><td>-1.946996</td><td>0.828053</td><td>-0.714268</td><td>-1.479062</td><td>1.497473</td><td>-0.258101</td><td>-0.869062</td><td>-0.141983</td><td>-0.133747</td><td>-0.81208</td><td>0.709349</td><td>-0.500305</td><td>-0.007074</td><td>-0.201015</td><td>-1.084597</td><td>-0.986371</td></tr><tr><td>0</td><td>-2.008016</td><td>-0.103537</td><td>-0.678877</td><td>1.293805</td><td>0.871848</td><td>0.772122</td><td>0.102028</td><td>-1.327589</td><td>-0.314823</td><td>-2.002148</td><td>2.028095</td><td>-1.405433</td><td>-0.993482</td><td>0.820124</td><td>-0.803125</td><td>1.004748</td><td>-0.837777</td><td>-0.191669</td><td>0.804184</td><td>-0.113826</td><td>0.924836</td><td>0.330462</td><td>-0.338266</td><td>0.126891</td><td>-1.529888</td><td>-1.431747</td><td>0.503322</td><td>-0.202119</td><td>0.115249</td><td>1.657061</td><td>-0.44093</td><td>-0.049486</td><td>-1.454701</td><td>0.187685</td><td>1.665249</td><td>0.082767</td><td>&hellip;</td><td>-0.307996</td><td>1.182974</td><td>2.21529</td><td>-0.155043</td><td>0.458012</td><td>-1.390214</td><td>-0.408432</td><td>0.337316</td><td>-0.089087</td><td>0.234207</td><td>-0.716889</td><td>1.149434</td><td>0.045183</td><td>0.401575</td><td>-0.28779</td><td>0.311514</td><td>-0.447858</td><td>-0.50225</td><td>-0.468958</td><td>-0.049302</td><td>0.520442</td><td>-1.368238</td><td>-1.746727</td><td>0.91828</td><td>-1.365611</td><td>-0.362411</td><td>-1.625111</td><td>-1.303448</td><td>-1.063129</td><td>0.411759</td><td>0.3335</td><td>0.696858</td><td>0.980887</td><td>-1.483994</td><td>-0.434004</td><td>-0.27822</td><td>-0.252438</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 101)\n",
       "┌────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ target ┆ column_0  ┆ column_1  ┆ column_2  ┆ … ┆ column_96 ┆ column_97 ┆ column_98 ┆ column_99 │\n",
       "│ ---    ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ i32    ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1      ┆ 1.294905  ┆ 0.333453  ┆ 0.352402  ┆ … ┆ 0.756591  ┆ 0.69854   ┆ 1.585823  ┆ 1.030014  │\n",
       "│ 1      ┆ 0.898777  ┆ -1.974316 ┆ 0.521609  ┆ … ┆ 1.903783  ┆ -2.402292 ┆ 0.298147  ┆ 1.011409  │\n",
       "│ 1      ┆ -0.22422  ┆ -0.514519 ┆ -0.752611 ┆ … ┆ -0.909764 ┆ 0.90272   ┆ -0.964569 ┆ -0.457124 │\n",
       "│ 1      ┆ -1.322002 ┆ 0.202279  ┆ 0.060536  ┆ … ┆ -0.007074 ┆ -0.201015 ┆ -1.084597 ┆ -0.986371 │\n",
       "│ 0      ┆ -2.008016 ┆ -0.103537 ┆ -0.678877 ┆ … ┆ -1.483994 ┆ -0.434004 ┆ -0.27822  ┆ -0.252438 │\n",
       "└────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = t.scale(df, cols=features, strategy=\"normal\")\n",
    "scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_0</th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_6</th>\n",
       "      <th>column_7</th>\n",
       "      <th>column_8</th>\n",
       "      <th>column_9</th>\n",
       "      <th>...</th>\n",
       "      <th>column_91</th>\n",
       "      <th>column_92</th>\n",
       "      <th>column_93</th>\n",
       "      <th>column_94</th>\n",
       "      <th>column_95</th>\n",
       "      <th>column_96</th>\n",
       "      <th>column_97</th>\n",
       "      <th>column_98</th>\n",
       "      <th>column_99</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.294911</td>\n",
       "      <td>0.333455</td>\n",
       "      <td>0.352404</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>1.479130</td>\n",
       "      <td>-2.306348</td>\n",
       "      <td>-0.238396</td>\n",
       "      <td>0.359758</td>\n",
       "      <td>-0.361002</td>\n",
       "      <td>0.574578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879121</td>\n",
       "      <td>-0.477688</td>\n",
       "      <td>-0.615772</td>\n",
       "      <td>0.542550</td>\n",
       "      <td>-0.605184</td>\n",
       "      <td>0.756594</td>\n",
       "      <td>0.698543</td>\n",
       "      <td>1.585831</td>\n",
       "      <td>1.030020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.898781</td>\n",
       "      <td>-1.974326</td>\n",
       "      <td>0.521612</td>\n",
       "      <td>-1.615613</td>\n",
       "      <td>-0.066947</td>\n",
       "      <td>0.541735</td>\n",
       "      <td>-0.722270</td>\n",
       "      <td>1.079216</td>\n",
       "      <td>-1.927831</td>\n",
       "      <td>0.342840</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.051960</td>\n",
       "      <td>0.388624</td>\n",
       "      <td>0.189536</td>\n",
       "      <td>-0.671453</td>\n",
       "      <td>0.529251</td>\n",
       "      <td>1.903792</td>\n",
       "      <td>-2.402304</td>\n",
       "      <td>0.298149</td>\n",
       "      <td>1.011414</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.224221</td>\n",
       "      <td>-0.514522</td>\n",
       "      <td>-0.752615</td>\n",
       "      <td>0.436604</td>\n",
       "      <td>-0.382392</td>\n",
       "      <td>0.329021</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>-0.166035</td>\n",
       "      <td>2.142457</td>\n",
       "      <td>-0.891157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332366</td>\n",
       "      <td>-1.189684</td>\n",
       "      <td>0.802021</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>0.218858</td>\n",
       "      <td>-0.909769</td>\n",
       "      <td>0.902725</td>\n",
       "      <td>-0.964574</td>\n",
       "      <td>-0.457126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.322008</td>\n",
       "      <td>0.202280</td>\n",
       "      <td>0.060536</td>\n",
       "      <td>-0.106601</td>\n",
       "      <td>0.504487</td>\n",
       "      <td>0.133591</td>\n",
       "      <td>0.453480</td>\n",
       "      <td>1.709956</td>\n",
       "      <td>-0.305260</td>\n",
       "      <td>0.373279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141984</td>\n",
       "      <td>-0.133748</td>\n",
       "      <td>-0.812084</td>\n",
       "      <td>0.709352</td>\n",
       "      <td>-0.500308</td>\n",
       "      <td>-0.007074</td>\n",
       "      <td>-0.201016</td>\n",
       "      <td>-1.084602</td>\n",
       "      <td>-0.986376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.008026</td>\n",
       "      <td>-0.103538</td>\n",
       "      <td>-0.678880</td>\n",
       "      <td>1.293811</td>\n",
       "      <td>0.871852</td>\n",
       "      <td>0.772125</td>\n",
       "      <td>0.102028</td>\n",
       "      <td>-1.327595</td>\n",
       "      <td>-0.314825</td>\n",
       "      <td>-2.002158</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.063134</td>\n",
       "      <td>0.411761</td>\n",
       "      <td>0.333501</td>\n",
       "      <td>0.696862</td>\n",
       "      <td>0.980892</td>\n",
       "      <td>-1.484001</td>\n",
       "      <td>-0.434006</td>\n",
       "      <td>-0.278222</td>\n",
       "      <td>-0.252439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_0  column_1  column_2  column_3  column_4  column_5  column_6   \n",
       "0  1.294911  0.333455  0.352404  1.108330  1.479130 -2.306348 -0.238396  \\\n",
       "1  0.898781 -1.974326  0.521612 -1.615613 -0.066947  0.541735 -0.722270   \n",
       "2 -0.224221 -0.514522 -0.752615  0.436604 -0.382392  0.329021  0.017661   \n",
       "3 -1.322008  0.202280  0.060536 -0.106601  0.504487  0.133591  0.453480   \n",
       "4 -2.008026 -0.103538 -0.678880  1.293811  0.871852  0.772125  0.102028   \n",
       "\n",
       "   column_7  column_8  column_9  ...  column_91  column_92  column_93   \n",
       "0  0.359758 -0.361002  0.574578  ...   0.879121  -0.477688  -0.615772  \\\n",
       "1  1.079216 -1.927831  0.342840  ...  -1.051960   0.388624   0.189536   \n",
       "2 -0.166035  2.142457 -0.891157  ...   0.332366  -1.189684   0.802021   \n",
       "3  1.709956 -0.305260  0.373279  ...  -0.141984  -0.133748  -0.812084   \n",
       "4 -1.327595 -0.314825 -2.002158  ...  -1.063134   0.411761   0.333501   \n",
       "\n",
       "   column_94  column_95  column_96  column_97  column_98  column_99  target  \n",
       "0   0.542550  -0.605184   0.756594   0.698543   1.585831   1.030020       1  \n",
       "1  -0.671453   0.529251   1.903792  -2.402304   0.298149   1.011414       1  \n",
       "2   0.012997   0.218858  -0.909769   0.902725  -0.964574  -0.457126       1  \n",
       "3   0.709352  -0.500308  -0.007074  -0.201016  -1.084602  -0.986376       1  \n",
       "4   0.696862   0.980892  -1.484001  -0.434006  -0.278222  -0.252439       0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The difference in result is caused by using ddof = 1 for sample variance in dsds\n",
    "# and using ddof = 0 in sklearn.\n",
    "\n",
    "# Long and convoluted code just to do some scaling...\n",
    "std = StandardScaler()\n",
    "scaled2 = std.fit_transform(df_pd[features], df_pd[target])\n",
    "# scaled2[:5, :] # scaled2 is a numpy matrix\n",
    "scaled2 = pd.DataFrame(scaled2, columns=features)\n",
    "scaled2[target] = df_pd[target]\n",
    "scaled2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.4 ms ± 411 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "scaled = t.scale(df, cols=features, strategy=\"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 ms ± 4.89 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "std = StandardScaler()\n",
    "scaled2 = std.fit_transform(df_pd[features], df_pd[target])\n",
    "scaled2 = pd.DataFrame(scaled2, columns=features)\n",
    "scaled2[target] = df_pd[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 101)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th><th>column_0</th><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th><th>column_8</th><th>column_9</th><th>column_10</th><th>column_11</th><th>column_12</th><th>column_13</th><th>column_14</th><th>column_15</th><th>column_16</th><th>column_17</th><th>column_18</th><th>column_19</th><th>column_20</th><th>column_21</th><th>column_22</th><th>column_23</th><th>column_24</th><th>column_25</th><th>column_26</th><th>column_27</th><th>column_28</th><th>column_29</th><th>column_30</th><th>column_31</th><th>column_32</th><th>column_33</th><th>column_34</th><th>column_35</th><th>&hellip;</th><th>column_63</th><th>column_64</th><th>column_65</th><th>column_66</th><th>column_67</th><th>column_68</th><th>column_69</th><th>column_70</th><th>column_71</th><th>column_72</th><th>column_73</th><th>column_74</th><th>column_75</th><th>column_76</th><th>column_77</th><th>column_78</th><th>column_79</th><th>column_80</th><th>column_81</th><th>column_82</th><th>column_83</th><th>column_84</th><th>column_85</th><th>column_86</th><th>column_87</th><th>column_88</th><th>column_89</th><th>column_90</th><th>column_91</th><th>column_92</th><th>column_93</th><th>column_94</th><th>column_95</th><th>column_96</th><th>column_97</th><th>column_98</th><th>column_99</th></tr><tr><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>5.986819</td><td>0.546596</td><td>1.648701</td><td>3.997167</td><td>7.458675</td><td>-10.106747</td><td>-1.624208</td><td>1.137966</td><td>-1.158476</td><td>2.997509</td><td>4.086229</td><td>-1.26675</td><td>-1.777032</td><td>-28.261351</td><td>30.073757</td><td>25.743075</td><td>-6.093473</td><td>0.064229</td><td>-0.318723</td><td>13.616268</td><td>-6.754464</td><td>-1.317529</td><td>3.310598</td><td>0.592153</td><td>0.423041</td><td>-2.356806</td><td>-33.492711</td><td>-2.162182</td><td>-1.672547</td><td>-0.452053</td><td>7.331551</td><td>19.98831</td><td>-3.633311</td><td>5.3967</td><td>15.262042</td><td>6.747133</td><td>&hellip;</td><td>-0.355568</td><td>-20.007311</td><td>0.619315</td><td>-7.78998</td><td>2.763447</td><td>3.997654</td><td>-0.956993</td><td>48.206937</td><td>3.92971</td><td>0.351252</td><td>-2.083404</td><td>-1.703559</td><td>4.076559</td><td>-2.069447</td><td>0.184148</td><td>0.450871</td><td>-5.936437</td><td>5.175711</td><td>-4.965513</td><td>-2.766612</td><td>-5.352892</td><td>15.179981</td><td>31.906209</td><td>0.483883</td><td>14.708496</td><td>-21.290712</td><td>-1.581163</td><td>-1.675474</td><td>4.842297</td><td>-12.407528</td><td>-2.956569</td><td>2.583529</td><td>-13.347925</td><td>17.690473</td><td>10.234511</td><td>6.890357</td><td>18.68473</td></tr><tr><td>1</td><td>4.147852</td><td>-10.166797</td><td>2.42494</td><td>-8.280883</td><td>0.694632</td><td>2.354545</td><td>-3.867516</td><td>4.401109</td><td>-8.34216</td><td>1.981496</td><td>-8.092609</td><td>2.311992</td><td>-1.925248</td><td>-53.891539</td><td>-12.550992</td><td>-15.345019</td><td>16.917992</td><td>7.096581</td><td>1.1973</td><td>-20.604139</td><td>-6.664765</td><td>-8.888499</td><td>-2.397954</td><td>4.17647</td><td>21.591129</td><td>-5.005256</td><td>-16.221116</td><td>0.459742</td><td>-0.690709</td><td>-0.269417</td><td>-3.044781</td><td>-25.934654</td><td>-0.610498</td><td>-7.233787</td><td>2.394237</td><td>1.998173</td><td>&hellip;</td><td>2.411827</td><td>10.014729</td><td>-5.52803</td><td>-32.598132</td><td>1.486695</td><td>33.294182</td><td>-4.239926</td><td>2.168909</td><td>-5.448569</td><td>7.679037</td><td>0.707344</td><td>-58.678729</td><td>12.111013</td><td>-13.529477</td><td>3.332116</td><td>0.214316</td><td>-0.885962</td><td>-0.134195</td><td>2.699072</td><td>3.252907</td><td>-29.258296</td><td>1.955882</td><td>54.63539</td><td>9.576148</td><td>3.437032</td><td>-0.501529</td><td>-18.291438</td><td>3.040755</td><td>-3.619622</td><td>5.837794</td><td>0.914736</td><td>-3.164613</td><td>8.694552</td><td>40.241724</td><td>-50.204775</td><td>0.888179</td><td>18.313636</td></tr><tr><td>1</td><td>-1.065503</td><td>-3.389961</td><td>-3.420557</td><td>0.969395</td><td>-0.685428</td><td>1.423848</td><td>-0.437088</td><td>-1.246797</td><td>10.319519</td><td>-3.428728</td><td>2.236986</td><td>-0.177996</td><td>-34.727854</td><td>6.973909</td><td>19.521618</td><td>0.671872</td><td>-30.380552</td><td>2.287781</td><td>7.248455</td><td>34.126478</td><td>-10.555192</td><td>1.861879</td><td>-0.576845</td><td>-5.463621</td><td>0.438259</td><td>-1.040704</td><td>6.654079</td><td>2.672152</td><td>2.830621</td><td>2.811892</td><td>-13.247055</td><td>-28.399984</td><td>-7.399742</td><td>0.051395</td><td>10.644678</td><td>-1.586821</td><td>&hellip;</td><td>-1.996005</td><td>13.915336</td><td>1.952686</td><td>6.921012</td><td>-0.136747</td><td>11.963771</td><td>1.013418</td><td>-9.571991</td><td>0.928034</td><td>-5.626219</td><td>7.528923</td><td>46.134983</td><td>15.170741</td><td>3.778057</td><td>8.584322</td><td>-7.137716</td><td>8.735825</td><td>2.60461</td><td>3.386294</td><td>-1.134204</td><td>-18.723313</td><td>2.136473</td><td>-20.611045</td><td>-0.88672</td><td>10.00448</td><td>51.431367</td><td>-6.196474</td><td>-1.776183</td><td>2.446435</td><td>-27.402815</td><td>3.859099</td><td>0.076166</td><td>2.663502</td><td>-15.066364</td><td>14.214258</td><td>-4.997656</td><td>-10.976358</td></tr><tr><td>1</td><td>-6.161803</td><td>-0.062358</td><td>0.309762</td><td>-1.479081</td><td>3.194638</td><td>0.56878</td><td>1.58343</td><td>7.261861</td><td>-0.902904</td><td>2.114949</td><td>-7.247418</td><td>2.592263</td><td>33.789852</td><td>-1.67435</td><td>-7.637536</td><td>9.335591</td><td>-21.62965</td><td>0.534352</td><td>4.499181</td><td>-11.933576</td><td>-3.985087</td><td>-3.348656</td><td>-7.057779</td><td>4.619226</td><td>-41.132171</td><td>1.753467</td><td>-1.937991</td><td>-9.15416</td><td>3.534515</td><td>0.43227</td><td>1.178357</td><td>-6.930231</td><td>5.532963</td><td>24.726412</td><td>-28.003835</td><td>-0.174675</td><td>&hellip;</td><td>2.075758</td><td>6.714418</td><td>6.689934</td><td>7.808172</td><td>1.958908</td><td>6.354117</td><td>-1.641288</td><td>26.176752</td><td>2.580099</td><td>0.569722</td><td>-6.041869</td><td>10.712468</td><td>-7.501954</td><td>0.153475</td><td>6.695536</td><td>-4.308605</td><td>-9.99083</td><td>-1.252156</td><td>-3.926162</td><td>10.932434</td><td>-3.135962</td><td>-32.845303</td><td>15.726288</td><td>-2.7377</td><td>-28.695589</td><td>28.466205</td><td>-8.143614</td><td>-4.502438</td><td>0.367855</td><td>-5.163827</td><td>-3.900286</td><td>3.373313</td><td>-11.310146</td><td>2.678528</td><td>-7.299003</td><td>-5.557134</td><td>-21.532237</td></tr><tr><td>0</td><td>-9.346525</td><td>-1.482052</td><td>-3.0823</td><td>4.833217</td><td>4.801851</td><td>3.362576</td><td>-0.04595</td><td>-6.515114</td><td>-0.946761</td><td>-8.299702</td><td>8.758147</td><td>-7.065284</td><td>-19.829434</td><td>11.72991</td><td>-15.416421</td><td>17.954306</td><td>-16.494773</td><td>-1.444415</td><td>4.670239</td><td>-0.473956</td><td>3.104503</td><td>1.078318</td><td>-2.020297</td><td>0.557246</td><td>-37.436009</td><td>-5.833064</td><td>13.483283</td><td>-1.901863</td><td>0.044479</td><td>7.748179</td><td>-6.716373</td><td>-1.218635</td><td>-7.470528</td><td>8.093139</td><td>36.106036</td><td>1.36148</td><td>&hellip;</td><td>-1.859693</td><td>21.998676</td><td>9.837191</td><td>-3.402064</td><td>2.081736</td><td>-26.483819</td><td>-2.293431</td><td>7.786315</td><td>0.620095</td><td>0.014286</td><td>-3.81728</td><td>21.605818</td><td>-2.640408</td><td>1.411127</td><td>-1.288832</td><td>0.95443</td><td>-1.590785</td><td>-3.234581</td><td>-2.168327</td><td>-0.689682</td><td>6.424369</td><td>-22.005775</td><td>-39.736955</td><td>4.62584</td><td>-26.503795</td><td>-6.597121</td><td>-33.573717</td><td>-6.494197</td><td>-3.668589</td><td>6.325084</td><td>1.606812</td><td>3.314172</td><td>17.470099</td><td>-26.354451</td><td>-11.840262</td><td>-1.798413</td><td>-6.893892</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 101)\n",
       "┌────────┬───────────┬────────────┬───────────┬───┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ target ┆ column_0  ┆ column_1   ┆ column_2  ┆ … ┆ column_96  ┆ column_97 ┆ column_98 ┆ column_99 │\n",
       "│ ---    ┆ ---       ┆ ---        ┆ ---       ┆   ┆ ---        ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ i32    ┆ f64       ┆ f64        ┆ f64       ┆   ┆ f64        ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════╪═══════════╪════════════╪═══════════╪═══╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1      ┆ 5.986819  ┆ 0.546596   ┆ 1.648701  ┆ … ┆ 17.690473  ┆ 10.234511 ┆ 6.890357  ┆ 18.68473  │\n",
       "│ 1      ┆ 4.147852  ┆ -10.166797 ┆ 2.42494   ┆ … ┆ 40.241724  ┆ -50.20477 ┆ 0.888179  ┆ 18.313636 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆ 5         ┆           ┆           │\n",
       "│ 1      ┆ -1.065503 ┆ -3.389961  ┆ -3.420557 ┆ … ┆ -15.066364 ┆ 14.214258 ┆ -4.997656 ┆ -10.97635 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆           ┆           ┆ 8         │\n",
       "│ 1      ┆ -6.161803 ┆ -0.062358  ┆ 0.309762  ┆ … ┆ 2.678528   ┆ -7.299003 ┆ -5.557134 ┆ -21.53223 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆           ┆           ┆ 7         │\n",
       "│ 0      ┆ -9.346525 ┆ -1.482052  ┆ -3.0823   ┆ … ┆ -26.354451 ┆ -11.84026 ┆ -1.798413 ┆ -6.893892 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆ 2         ┆           ┆           │\n",
       "└────────┴───────────┴────────────┴───────────┴───┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.impute(df, cols=features, strategy=\"median\").head() # 8.29 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>column_0</th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_6</th>\n",
       "      <th>column_7</th>\n",
       "      <th>column_8</th>\n",
       "      <th>...</th>\n",
       "      <th>column_90</th>\n",
       "      <th>column_91</th>\n",
       "      <th>column_92</th>\n",
       "      <th>column_93</th>\n",
       "      <th>column_94</th>\n",
       "      <th>column_95</th>\n",
       "      <th>column_96</th>\n",
       "      <th>column_97</th>\n",
       "      <th>column_98</th>\n",
       "      <th>column_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.986819</td>\n",
       "      <td>0.546596</td>\n",
       "      <td>1.648701</td>\n",
       "      <td>3.997167</td>\n",
       "      <td>7.458675</td>\n",
       "      <td>-10.106747</td>\n",
       "      <td>-1.624208</td>\n",
       "      <td>1.137966</td>\n",
       "      <td>-1.158476</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.675474</td>\n",
       "      <td>4.842297</td>\n",
       "      <td>-12.407528</td>\n",
       "      <td>-2.956569</td>\n",
       "      <td>2.583529</td>\n",
       "      <td>-13.347925</td>\n",
       "      <td>17.690473</td>\n",
       "      <td>10.234511</td>\n",
       "      <td>6.890357</td>\n",
       "      <td>18.684730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.147852</td>\n",
       "      <td>-10.166797</td>\n",
       "      <td>2.424940</td>\n",
       "      <td>-8.280883</td>\n",
       "      <td>0.694632</td>\n",
       "      <td>2.354545</td>\n",
       "      <td>-3.867516</td>\n",
       "      <td>4.401109</td>\n",
       "      <td>-8.342160</td>\n",
       "      <td>...</td>\n",
       "      <td>3.040755</td>\n",
       "      <td>-3.619622</td>\n",
       "      <td>5.837794</td>\n",
       "      <td>0.914736</td>\n",
       "      <td>-3.164613</td>\n",
       "      <td>8.694552</td>\n",
       "      <td>40.241724</td>\n",
       "      <td>-50.204775</td>\n",
       "      <td>0.888179</td>\n",
       "      <td>18.313636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.065503</td>\n",
       "      <td>-3.389961</td>\n",
       "      <td>-3.420557</td>\n",
       "      <td>0.969395</td>\n",
       "      <td>-0.685428</td>\n",
       "      <td>1.423848</td>\n",
       "      <td>-0.437088</td>\n",
       "      <td>-1.246797</td>\n",
       "      <td>10.319519</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.776183</td>\n",
       "      <td>2.446435</td>\n",
       "      <td>-27.402815</td>\n",
       "      <td>3.859099</td>\n",
       "      <td>0.076166</td>\n",
       "      <td>2.663502</td>\n",
       "      <td>-15.066364</td>\n",
       "      <td>14.214258</td>\n",
       "      <td>-4.997656</td>\n",
       "      <td>-10.976358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.161803</td>\n",
       "      <td>-0.062358</td>\n",
       "      <td>0.309762</td>\n",
       "      <td>-1.479081</td>\n",
       "      <td>3.194638</td>\n",
       "      <td>0.568780</td>\n",
       "      <td>1.583430</td>\n",
       "      <td>7.261861</td>\n",
       "      <td>-0.902904</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.502438</td>\n",
       "      <td>0.367855</td>\n",
       "      <td>-5.163827</td>\n",
       "      <td>-3.900286</td>\n",
       "      <td>3.373313</td>\n",
       "      <td>-11.310146</td>\n",
       "      <td>2.678528</td>\n",
       "      <td>-7.299003</td>\n",
       "      <td>-5.557134</td>\n",
       "      <td>-21.532237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.346525</td>\n",
       "      <td>-1.482052</td>\n",
       "      <td>-3.082300</td>\n",
       "      <td>4.833217</td>\n",
       "      <td>4.801851</td>\n",
       "      <td>3.362576</td>\n",
       "      <td>-0.045950</td>\n",
       "      <td>-6.515114</td>\n",
       "      <td>-0.946761</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.494197</td>\n",
       "      <td>-3.668589</td>\n",
       "      <td>6.325084</td>\n",
       "      <td>1.606812</td>\n",
       "      <td>3.314172</td>\n",
       "      <td>17.470099</td>\n",
       "      <td>-26.354451</td>\n",
       "      <td>-11.840262</td>\n",
       "      <td>-1.798413</td>\n",
       "      <td>-6.893892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  column_0   column_1  column_2  column_3  column_4   column_5   \n",
       "0     1.0  5.986819   0.546596  1.648701  3.997167  7.458675 -10.106747  \\\n",
       "1     1.0  4.147852 -10.166797  2.424940 -8.280883  0.694632   2.354545   \n",
       "2     1.0 -1.065503  -3.389961 -3.420557  0.969395 -0.685428   1.423848   \n",
       "3     1.0 -6.161803  -0.062358  0.309762 -1.479081  3.194638   0.568780   \n",
       "4     0.0 -9.346525  -1.482052 -3.082300  4.833217  4.801851   3.362576   \n",
       "\n",
       "   column_6  column_7   column_8  ...  column_90  column_91  column_92   \n",
       "0 -1.624208  1.137966  -1.158476  ...  -1.675474   4.842297 -12.407528  \\\n",
       "1 -3.867516  4.401109  -8.342160  ...   3.040755  -3.619622   5.837794   \n",
       "2 -0.437088 -1.246797  10.319519  ...  -1.776183   2.446435 -27.402815   \n",
       "3  1.583430  7.261861  -0.902904  ...  -4.502438   0.367855  -5.163827   \n",
       "4 -0.045950 -6.515114  -0.946761  ...  -6.494197  -3.668589   6.325084   \n",
       "\n",
       "   column_93  column_94  column_95  column_96  column_97  column_98  column_99  \n",
       "0  -2.956569   2.583529 -13.347925  17.690473  10.234511   6.890357  18.684730  \n",
       "1   0.914736  -3.164613   8.694552  40.241724 -50.204775   0.888179  18.313636  \n",
       "2   3.859099   0.076166   2.663502 -15.066364  14.214258  -4.997656 -10.976358  \n",
       "3  -3.900286   3.373313 -11.310146   2.678528  -7.299003  -5.557134 -21.532237  \n",
       "4   1.606812   3.314172  17.470099 -26.354451 -11.840262  -1.798413  -6.893892  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer # 1.25s\n",
    "\n",
    "imputer = SimpleImputer(strategy = \"median\")\n",
    "imputed = pd.DataFrame(imputer.fit_transform(df_pd, df_pd[target]), columns=df.columns)\n",
    "imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.29 ms ± 56.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "t.impute(df, cols=features, strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25 s ± 9.45 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "imputer = SimpleImputer(strategy = \"median\")\n",
    "imputed = pd.DataFrame(imputer.fit_transform(df_pd, df_pd[target]), columns=df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dsds.fs as fs # fs = feature_selection\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent 0.02s in computing Fscore.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>feature</th><th>f_value</th><th>p_value</th></tr><tr><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;column_0&quot;</td><td>1.147982</td><td>0.283975</td></tr><tr><td>&quot;column_1&quot;</td><td>8.6081e-7</td><td>0.99926</td></tr><tr><td>&quot;column_2&quot;</td><td>0.160483</td><td>0.688713</td></tr><tr><td>&quot;column_3&quot;</td><td>0.381542</td><td>0.536781</td></tr><tr><td>&quot;column_4&quot;</td><td>0.00059</td><td>0.980622</td></tr><tr><td>&quot;column_5&quot;</td><td>0.020556</td><td>0.885995</td></tr><tr><td>&quot;column_6&quot;</td><td>1205.834997</td><td>1.2189e-262</td></tr><tr><td>&quot;column_7&quot;</td><td>1199.187486</td><td>3.2619e-261</td></tr><tr><td>&quot;column_8&quot;</td><td>1211.524308</td><td>7.3161e-264</td></tr><tr><td>&quot;column_9&quot;</td><td>1262.539049</td><td>8.1865e-275</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 3)\n",
       "┌──────────┬─────────────┬─────────────┐\n",
       "│ feature  ┆ f_value     ┆ p_value     │\n",
       "│ ---      ┆ ---         ┆ ---         │\n",
       "│ str      ┆ f64         ┆ f64         │\n",
       "╞══════════╪═════════════╪═════════════╡\n",
       "│ column_0 ┆ 1.147982    ┆ 0.283975    │\n",
       "│ column_1 ┆ 8.6081e-7   ┆ 0.99926     │\n",
       "│ column_2 ┆ 0.160483    ┆ 0.688713    │\n",
       "│ column_3 ┆ 0.381542    ┆ 0.536781    │\n",
       "│ …        ┆ …           ┆ …           │\n",
       "│ column_6 ┆ 1205.834997 ┆ 1.2189e-262 │\n",
       "│ column_7 ┆ 1199.187486 ┆ 3.2619e-261 │\n",
       "│ column_8 ┆ 1211.524308 ┆ 7.3161e-264 │\n",
       "│ column_9 ┆ 1262.539049 ┆ 8.1865e-275 │\n",
       "└──────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "res = fs.f_classif(df, target=target)\n",
    "end = perf_counter()\n",
    "print(f\"Spent {end - start:.2f}s in computing Fscore.\")\n",
    "res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent 0.12s in computing Fscore.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>f_value</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>column_0</td>\n",
       "      <td>1.147982e+00</td>\n",
       "      <td>2.839746e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>column_1</td>\n",
       "      <td>8.608100e-07</td>\n",
       "      <td>9.992597e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>column_2</td>\n",
       "      <td>1.604831e-01</td>\n",
       "      <td>6.887130e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>column_3</td>\n",
       "      <td>3.815420e-01</td>\n",
       "      <td>5.367805e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>column_4</td>\n",
       "      <td>5.899596e-04</td>\n",
       "      <td>9.806221e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>column_5</td>\n",
       "      <td>2.055620e-02</td>\n",
       "      <td>8.859948e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>column_6</td>\n",
       "      <td>1.205835e+03</td>\n",
       "      <td>1.218853e-262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>column_7</td>\n",
       "      <td>1.199187e+03</td>\n",
       "      <td>3.261909e-261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>column_8</td>\n",
       "      <td>1.211524e+03</td>\n",
       "      <td>7.316090e-264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>column_9</td>\n",
       "      <td>1.262539e+03</td>\n",
       "      <td>8.186518e-275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature       f_value        p_value\n",
       "0  column_0  1.147982e+00   2.839746e-01\n",
       "1  column_1  8.608100e-07   9.992597e-01\n",
       "2  column_2  1.604831e-01   6.887130e-01\n",
       "3  column_3  3.815420e-01   5.367805e-01\n",
       "4  column_4  5.899596e-04   9.806221e-01\n",
       "5  column_5  2.055620e-02   8.859948e-01\n",
       "6  column_6  1.205835e+03  1.218853e-262\n",
       "7  column_7  1.199187e+03  3.261909e-261\n",
       "8  column_8  1.211524e+03  7.316090e-264\n",
       "9  column_9  1.262539e+03  8.186518e-275"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "f, pv = f_classif(df_pd[features], df_pd[target])\n",
    "res = pd.DataFrame({\"feature\":features, \"f_value\":f, \"p_value\":pv})\n",
    "end = perf_counter()\n",
    "print(f\"Spent {end - start:.2f}s in computing Fscore.\")\n",
    "res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent  0.05s in computing Fscore.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>f_value</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>column_0</td>\n",
       "      <td>1.147982e+00</td>\n",
       "      <td>2.839746e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>column_1</td>\n",
       "      <td>8.608105e-07</td>\n",
       "      <td>9.992597e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>column_2</td>\n",
       "      <td>1.604831e-01</td>\n",
       "      <td>6.887130e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>column_3</td>\n",
       "      <td>3.815420e-01</td>\n",
       "      <td>5.367805e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>column_4</td>\n",
       "      <td>5.899596e-04</td>\n",
       "      <td>9.806221e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>column_5</td>\n",
       "      <td>2.055620e-02</td>\n",
       "      <td>8.859948e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>column_6</td>\n",
       "      <td>1.205835e+03</td>\n",
       "      <td>1.218853e-262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>column_7</td>\n",
       "      <td>1.199187e+03</td>\n",
       "      <td>3.261909e-261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>column_8</td>\n",
       "      <td>1.211524e+03</td>\n",
       "      <td>7.316090e-264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>column_9</td>\n",
       "      <td>1.262539e+03</td>\n",
       "      <td>8.186518e-275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature       f_value        p_value\n",
       "0  column_0  1.147982e+00   2.839746e-01\n",
       "1  column_1  8.608105e-07   9.992597e-01\n",
       "2  column_2  1.604831e-01   6.887130e-01\n",
       "3  column_3  3.815420e-01   5.367805e-01\n",
       "4  column_4  5.899596e-04   9.806221e-01\n",
       "5  column_5  2.055620e-02   8.859948e-01\n",
       "6  column_6  1.205835e+03  1.218853e-262\n",
       "7  column_7  1.199187e+03  3.261909e-261\n",
       "8  column_8  1.211524e+03  7.316090e-264\n",
       "9  column_9  1.262539e+03  8.186518e-275"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "f, pv = f_regression(df_pd[features], df_pd[target])\n",
    "res = pd.DataFrame({\"feature\":features, \"f_value\":f, \"p_value\":pv})\n",
    "end = perf_counter()\n",
    "print(f\"Spent {end - start: .2f}s in computing Fscore.\")\n",
    "res.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Information Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mutual Info: 100%|██████████| 100/100 [00:07<00:00, 13.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>feature</th><th>estimated_mi</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;column_47&quot;</td><td>0.027364</td></tr><tr><td>&quot;column_93&quot;</td><td>0.022182</td></tr><tr><td>&quot;column_40&quot;</td><td>0.016389</td></tr><tr><td>&quot;column_99&quot;</td><td>0.015347</td></tr><tr><td>&quot;column_33&quot;</td><td>0.014182</td></tr><tr><td>&quot;column_29&quot;</td><td>0.013522</td></tr><tr><td>&quot;column_50&quot;</td><td>0.012938</td></tr><tr><td>&quot;column_38&quot;</td><td>0.012355</td></tr><tr><td>&quot;column_37&quot;</td><td>0.011551</td></tr><tr><td>&quot;column_70&quot;</td><td>0.011321</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌───────────┬──────────────┐\n",
       "│ feature   ┆ estimated_mi │\n",
       "│ ---       ┆ ---          │\n",
       "│ str       ┆ f64          │\n",
       "╞═══════════╪══════════════╡\n",
       "│ column_47 ┆ 0.027364     │\n",
       "│ column_93 ┆ 0.022182     │\n",
       "│ column_40 ┆ 0.016389     │\n",
       "│ column_99 ┆ 0.015347     │\n",
       "│ …         ┆ …            │\n",
       "│ column_50 ┆ 0.012938     │\n",
       "│ column_38 ┆ 0.012355     │\n",
       "│ column_37 ┆ 0.011551     │\n",
       "│ column_70 ┆ 0.011321     │\n",
       "└───────────┴──────────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Took 7.4s\n",
    "fs.mutual_info(df, target=target, conti_cols=features).sort(by=\"estimated_mi\", descending=True).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_mi_sklearn(df:pd.DataFrame, cols:list[str], target:str, k=3, random_state:int=42):\n",
    "    mi_estimates = mutual_info_classif(df[cols], df[target]\n",
    "                        , n_neighbors=k, random_state=random_state, discrete_features=False)\n",
    "\n",
    "    return pl.from_records([cols, mi_estimates], schema=[\"feature\", \"estimated_mi\"]).sort(\"estimated_mi\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>feature</th><th>estimated_mi</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;column_47&quot;</td><td>0.027364</td></tr><tr><td>&quot;column_93&quot;</td><td>0.022182</td></tr><tr><td>&quot;column_40&quot;</td><td>0.016391</td></tr><tr><td>&quot;column_99&quot;</td><td>0.015345</td></tr><tr><td>&quot;column_33&quot;</td><td>0.014182</td></tr><tr><td>&quot;column_29&quot;</td><td>0.013522</td></tr><tr><td>&quot;column_50&quot;</td><td>0.01294</td></tr><tr><td>&quot;column_38&quot;</td><td>0.012355</td></tr><tr><td>&quot;column_37&quot;</td><td>0.01155</td></tr><tr><td>&quot;column_70&quot;</td><td>0.01132</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌───────────┬──────────────┐\n",
       "│ feature   ┆ estimated_mi │\n",
       "│ ---       ┆ ---          │\n",
       "│ str       ┆ f64          │\n",
       "╞═══════════╪══════════════╡\n",
       "│ column_47 ┆ 0.027364     │\n",
       "│ column_93 ┆ 0.022182     │\n",
       "│ column_40 ┆ 0.016391     │\n",
       "│ column_99 ┆ 0.015345     │\n",
       "│ …         ┆ …            │\n",
       "│ column_50 ┆ 0.01294      │\n",
       "│ column_38 ┆ 0.012355     │\n",
       "│ column_37 ┆ 0.01155      │\n",
       "│ column_70 ┆ 0.01132      │\n",
       "└───────────┴──────────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Took 1m38s seconds by using sklearn. The reason is that sklearn's implementation did not turn on multithreading for KDtrees.\n",
    "# Sklearn also did not provide an option to turn it on, despite the fact that sklearn's KDtrees\n",
    "# does have this functionality.\n",
    "estimate_mi_sklearn(df_pd, cols=features, target=target).limit(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRMR Feature selection Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrmr import mrmr_classif # This is currently the most starred MRMR Python package on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to wrap it so that we get apples to apples comparison\n",
    "def mrmr_package(df:pd.DataFrame, target:str, k:int) -> list[str]:\n",
    "    features = list(df.columns)\n",
    "    features.remove(target)\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    start = perf_counter()\n",
    "    output = mrmr_classif(X, y, K = k)\n",
    "    end = perf_counter()\n",
    "    print(f\"Spent {end - start:.2f}s to compute mrmr.\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:10<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent 14.31s to compute mrmr.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['column_47',\n",
       " 'column_63',\n",
       " 'column_78',\n",
       " 'column_54',\n",
       " 'column_93',\n",
       " 'column_79',\n",
       " 'column_48',\n",
       " 'column_69',\n",
       " 'column_39',\n",
       " 'column_10',\n",
       " 'column_98',\n",
       " 'column_17',\n",
       " 'column_29',\n",
       " 'column_86',\n",
       " 'column_6',\n",
       " 'column_33',\n",
       " 'column_9',\n",
       " 'column_82',\n",
       " 'column_55',\n",
       " 'column_21',\n",
       " 'column_13',\n",
       " 'column_37',\n",
       " 'column_25',\n",
       " 'column_76',\n",
       " 'column_40',\n",
       " 'column_22',\n",
       " 'column_11',\n",
       " 'column_28',\n",
       " 'column_8',\n",
       " 'column_73',\n",
       " 'column_56',\n",
       " 'column_52',\n",
       " 'column_36',\n",
       " 'column_90',\n",
       " 'column_7',\n",
       " 'column_70',\n",
       " 'column_50',\n",
       " 'column_38',\n",
       " 'column_99',\n",
       " 'column_41',\n",
       " 'column_83',\n",
       " 'column_45',\n",
       " 'column_96',\n",
       " 'column_34',\n",
       " 'column_97',\n",
       " 'column_26',\n",
       " 'column_42',\n",
       " 'column_87',\n",
       " 'column_68',\n",
       " 'column_84']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrmr_package(df_pd, \"target\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fscore to determine feature relevance...\n",
      "Found 100 total features to select from. Proceeding to select top 50 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MRMR, fscore: 100%|██████████| 50/50 [00:00<00:00, 195.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output is sorted in order of selection (relevance).\n",
      "Spent 0.30s in computing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['column_47',\n",
       " 'column_63',\n",
       " 'column_78',\n",
       " 'column_54',\n",
       " 'column_93',\n",
       " 'column_79',\n",
       " 'column_48',\n",
       " 'column_69',\n",
       " 'column_39',\n",
       " 'column_10',\n",
       " 'column_98',\n",
       " 'column_17',\n",
       " 'column_29',\n",
       " 'column_86',\n",
       " 'column_6',\n",
       " 'column_33',\n",
       " 'column_9',\n",
       " 'column_82',\n",
       " 'column_55',\n",
       " 'column_21',\n",
       " 'column_13',\n",
       " 'column_37',\n",
       " 'column_25',\n",
       " 'column_76',\n",
       " 'column_40',\n",
       " 'column_22',\n",
       " 'column_11',\n",
       " 'column_28',\n",
       " 'column_8',\n",
       " 'column_73',\n",
       " 'column_56',\n",
       " 'column_52',\n",
       " 'column_36',\n",
       " 'column_90',\n",
       " 'column_7',\n",
       " 'column_70',\n",
       " 'column_50',\n",
       " 'column_38',\n",
       " 'column_99',\n",
       " 'column_41',\n",
       " 'column_83',\n",
       " 'column_45',\n",
       " 'column_96',\n",
       " 'column_34',\n",
       " 'column_97',\n",
       " 'column_26',\n",
       " 'column_42',\n",
       " 'column_87',\n",
       " 'column_68',\n",
       " 'column_84']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "res = fs.mrmr(df, target=\"target\", k = 50, low_memory=False)\n",
    "end = perf_counter()\n",
    "print(f\"Spent {end - start:.2f}s in computing.\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fscore to determine feature relevance...\n",
      "Found 100 total features to select from. Proceeding to select top 50 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MRMR, fscore: 100%|██████████| 50/50 [00:01<00:00, 46.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output is sorted in order of selection (relevance).\n",
      "Spent 1.09s in computing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['column_47',\n",
       " 'column_63',\n",
       " 'column_78',\n",
       " 'column_54',\n",
       " 'column_93',\n",
       " 'column_79',\n",
       " 'column_48',\n",
       " 'column_69',\n",
       " 'column_39',\n",
       " 'column_10',\n",
       " 'column_98',\n",
       " 'column_17',\n",
       " 'column_29',\n",
       " 'column_86',\n",
       " 'column_6',\n",
       " 'column_33',\n",
       " 'column_9',\n",
       " 'column_82',\n",
       " 'column_55',\n",
       " 'column_21',\n",
       " 'column_13',\n",
       " 'column_37',\n",
       " 'column_25',\n",
       " 'column_76',\n",
       " 'column_40',\n",
       " 'column_22',\n",
       " 'column_11',\n",
       " 'column_28',\n",
       " 'column_8',\n",
       " 'column_73',\n",
       " 'column_56',\n",
       " 'column_52',\n",
       " 'column_36',\n",
       " 'column_90',\n",
       " 'column_7',\n",
       " 'column_70',\n",
       " 'column_50',\n",
       " 'column_38',\n",
       " 'column_99',\n",
       " 'column_41',\n",
       " 'column_83',\n",
       " 'column_45',\n",
       " 'column_96',\n",
       " 'column_34',\n",
       " 'column_97',\n",
       " 'column_26',\n",
       " 'column_42',\n",
       " 'column_87',\n",
       " 'column_68',\n",
       " 'column_84']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "res = fs.mrmr(df, target=\"target\", k = 50, low_memory=True)\n",
    "end = perf_counter()\n",
    "print(f\"Spent {end - start:.2f}s in computing.\")\n",
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring best paramters: 100%|██████████| 100/100 [00:01<00:00, 61.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent 1.74s in computing.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 101)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th><th>column_0</th><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th><th>column_8</th><th>column_9</th><th>column_10</th><th>column_11</th><th>column_12</th><th>column_13</th><th>column_14</th><th>column_15</th><th>column_16</th><th>column_17</th><th>column_18</th><th>column_19</th><th>column_20</th><th>column_21</th><th>column_22</th><th>column_23</th><th>column_24</th><th>column_25</th><th>column_26</th><th>column_27</th><th>column_28</th><th>column_29</th><th>column_30</th><th>column_31</th><th>column_32</th><th>column_33</th><th>column_34</th><th>column_35</th><th>&hellip;</th><th>column_63</th><th>column_64</th><th>column_65</th><th>column_66</th><th>column_67</th><th>column_68</th><th>column_69</th><th>column_70</th><th>column_71</th><th>column_72</th><th>column_73</th><th>column_74</th><th>column_75</th><th>column_76</th><th>column_77</th><th>column_78</th><th>column_79</th><th>column_80</th><th>column_81</th><th>column_82</th><th>column_83</th><th>column_84</th><th>column_85</th><th>column_86</th><th>column_87</th><th>column_88</th><th>column_89</th><th>column_90</th><th>column_91</th><th>column_92</th><th>column_93</th><th>column_94</th><th>column_95</th><th>column_96</th><th>column_97</th><th>column_98</th><th>column_99</th></tr><tr><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>6.01535</td><td>0.546501</td><td>1.643836</td><td>4.002086</td><td>7.452206</td><td>-9.771592</td><td>-1.623333</td><td>1.134822</td><td>-1.164929</td><td>3.014361</td><td>4.08917</td><td>-1.261647</td><td>-1.775636</td><td>-28.118007</td><td>30.299479</td><td>25.973076</td><td>-6.294637</td><td>0.064228</td><td>-0.318748</td><td>13.56766</td><td>-6.786885</td><td>-1.320511</td><td>3.311371</td><td>0.59225</td><td>0.423113</td><td>-2.369111</td><td>-33.785555</td><td>-2.162067</td><td>-1.682431</td><td>-0.450174</td><td>7.290018</td><td>19.726521</td><td>-3.624857</td><td>5.40707</td><td>15.260811</td><td>6.728758</td><td>&hellip;</td><td>-0.356182</td><td>-20.080501</td><td>0.617387</td><td>-7.7774</td><td>2.751548</td><td>4.008117</td><td>-0.956815</td><td>50.097601</td><td>3.929083</td><td>0.351059</td><td>-2.091347</td><td>-1.705404</td><td>4.066172</td><td>-2.060925</td><td>0.184058</td><td>0.450799</td><td>-5.900022</td><td>5.167614</td><td>-4.940943</td><td>-2.765675</td><td>-5.349584</td><td>15.061502</td><td>31.952164</td><td>0.483696</td><td>14.818224</td><td>-21.352494</td><td>-1.581689</td><td>-1.686986</td><td>4.864902</td><td>-12.43688</td><td>-2.95384</td><td>2.58419</td><td>-13.517491</td><td>17.64964</td><td>10.209761</td><td>6.877143</td><td>18.462875</td></tr><tr><td>1</td><td>4.163948</td><td>-10.179248</td><td>2.415587</td><td>-8.265827</td><td>0.694511</td><td>2.389893</td><td>-3.86382</td><td>4.370761</td><td>-8.504408</td><td>1.989947</td><td>-8.084204</td><td>2.326432</td><td>-1.923648</td><td>-53.554437</td><td>-12.484463</td><td>-15.233791</td><td>16.062962</td><td>7.091787</td><td>1.197016</td><td>-20.691494</td><td>-6.696535</td><td>-8.95381</td><td>-2.397499</td><td>4.179303</td><td>21.63621</td><td>-5.046817</td><td>-16.329346</td><td>0.459749</td><td>-0.692747</td><td>-0.268715</td><td>-3.055319</td><td>-26.314749</td><td>-0.610116</td><td>-7.217608</td><td>2.394165</td><td>1.995562</td><td>&hellip;</td><td>2.392748</td><td>9.987499</td><td>-5.60925</td><td>-32.50317</td><td>1.482527</td><td>33.522215</td><td>-4.237712</td><td>2.18819</td><td>-5.449617</td><td>7.640678</td><td>0.706169</td><td>-59.026756</td><td>12.057204</td><td>-13.372738</td><td>3.315109</td><td>0.214299</td><td>-0.88445</td><td>-0.134207</td><td>2.708359</td><td>3.254129</td><td>-29.220057</td><td>1.950917</td><td>54.728883</td><td>9.547878</td><td>3.449203</td><td>-0.501669</td><td>-18.315018</td><td>3.009795</td><td>-3.605438</td><td>5.828239</td><td>0.915098</td><td>-3.163691</td><td>8.60486</td><td>40.117015</td><td>-50.42668</td><td>0.887741</td><td>18.097888</td></tr><tr><td>1</td><td>-1.063884</td><td>-3.392264</td><td>-3.437086</td><td>0.969839</td><td>-0.685547</td><td>1.438776</td><td>-0.437007</td><td>-1.250506</td><td>10.102604</td><td>-3.407911</td><td>2.238085</td><td>-0.177865</td><td>-34.605424</td><td>6.993467</td><td>19.646566</td><td>0.672563</td><td>-32.418748</td><td>2.286989</td><td>7.24303</td><td>33.953944</td><td>-10.618171</td><td>1.856469</td><td>-0.576808</td><td>-5.459312</td><td>0.438337</td><td>-1.043689</td><td>6.624811</td><td>2.672316</td><td>2.806871</td><td>2.860568</td><td>-13.346692</td><td>-28.83001</td><td>-7.37424</td><td>0.051397</td><td>10.643944</td><td>-1.588582</td><td>&hellip;</td><td>-2.010012</td><td>13.871558</td><td>1.937844</td><td>6.93156</td><td>-0.136795</td><td>12.018818</td><td>1.013615</td><td>-9.376114</td><td>0.92798</td><td>-5.650259</td><td>7.467845</td><td>45.88215</td><td>15.096535</td><td>3.801133</td><td>8.510789</td><td>-7.14567</td><td>8.80152</td><td>2.601917</td><td>3.399748</td><td>-1.134001</td><td>-18.702572</td><td>2.130709</td><td>-20.585739</td><td>-0.887293</td><td>10.067413</td><td>51.230694</td><td>-6.201338</td><td>-1.788912</td><td>2.453942</td><td>-27.491511</td><td>3.863301</td><td>0.076167</td><td>2.649376</td><td>-15.099021</td><td>14.174526</td><td>-5.005744</td><td>-11.08174</td></tr><tr><td>1</td><td>-6.132151</td><td>-0.06236</td><td>0.309533</td><td>-1.478143</td><td>3.192917</td><td>0.571616</td><td>1.584268</td><td>7.196294</td><td>-0.907031</td><td>2.124386</td><td>-7.240294</td><td>2.609738</td><td>33.908335</td><td>-1.672402</td><td>-7.605418</td><td>9.390299</td><td>-22.908023</td><td>0.534292</td><td>4.496577</td><td>-11.973959</td><td>-3.999367</td><td>-3.363067</td><td>-7.055254</td><td>4.622547</td><td>-41.02493</td><td>1.746052</td><td>-1.942035</td><td>-9.153041</td><td>3.500459</td><td>0.434007</td><td>1.176271</td><td>-6.987514</td><td>5.549403</td><td>24.820718</td><td>-28.006685</td><td>-0.174704</td><td>&hellip;</td><td>2.06092</td><td>6.699404</td><td>6.583106</td><td>7.820819</td><td>1.952212</td><td>6.375653</td><td>-1.640827</td><td>27.011342</td><td>2.579783</td><td>0.569243</td><td>-6.086016</td><td>10.678634</td><td>-7.528681</td><td>0.153545</td><td>6.644857</td><td>-4.312254</td><td>-9.911476</td><td>-1.252926</td><td>-3.909188</td><td>10.940284</td><td>-3.134546</td><td>-33.191383</td><td>15.743654</td><td>-2.74174</td><td>-28.421506</td><td>28.374653</td><td>-8.15096</td><td>-4.561316</td><td>0.368105</td><td>-5.171747</td><td>-3.896017</td><td>3.374336</td><td>-11.443679</td><td>2.676197</td><td>-7.314035</td><td>-5.566668</td><td>-21.805974</td></tr><tr><td>0</td><td>-9.291163</td><td>-1.482626</td><td>-3.096258</td><td>4.839853</td><td>4.798556</td><td>3.426212</td><td>-0.045949</td><td>-6.571324</td><td>-0.951256</td><td>-8.217974</td><td>8.767611</td><td>-6.9809</td><td>-19.77228</td><td>11.772089</td><td>-15.327262</td><td>18.094168</td><td>-17.368863</td><td>-1.444776</td><td>4.667478</td><td>-0.474142</td><td>3.094988</td><td>1.076232</td><td>-2.019956</td><td>0.557333</td><td>-37.341341</td><td>-5.885747</td><td>13.400606</td><td>-1.90177</td><td>0.044469</td><td>7.988633</td><td>-6.752991</td><td>-1.221941</td><td>-7.444659</td><td>8.112333</td><td>36.102028</td><td>1.360132</td><td>&hellip;</td><td>-1.872109</td><td>21.915579</td><td>9.647685</td><td>-3.398592</td><td>2.074315</td><td>-26.317529</td><td>-2.292617</td><td>7.93382</td><td>0.620069</td><td>0.014286</td><td>-3.83879</td><td>21.514532</td><td>-2.64556</td><td>1.415559</td><td>-1.292264</td><td>0.954145</td><td>-1.586525</td><td>-3.238427</td><td>-2.161905</td><td>-0.6896</td><td>6.428751</td><td>-22.206565</td><td>-39.675484</td><td>4.616468</td><td>-26.257655</td><td>-6.608475</td><td>-33.627763</td><td>-6.598112</td><td>-3.654096</td><td>6.314281</td><td>1.607791</td><td>3.315166</td><td>17.225647</td><td>-26.425384</td><td>-11.870934</td><td>-1.799935</td><td>-6.94673</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 101)\n",
       "┌────────┬───────────┬────────────┬───────────┬───┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ target ┆ column_0  ┆ column_1   ┆ column_2  ┆ … ┆ column_96  ┆ column_97 ┆ column_98 ┆ column_99 │\n",
       "│ ---    ┆ ---       ┆ ---        ┆ ---       ┆   ┆ ---        ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ i32    ┆ f64       ┆ f64        ┆ f64       ┆   ┆ f64        ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════╪═══════════╪════════════╪═══════════╪═══╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1      ┆ 6.01535   ┆ 0.546501   ┆ 1.643836  ┆ … ┆ 17.64964   ┆ 10.209761 ┆ 6.877143  ┆ 18.462875 │\n",
       "│ 1      ┆ 4.163948  ┆ -10.179248 ┆ 2.415587  ┆ … ┆ 40.117015  ┆ -50.42668 ┆ 0.887741  ┆ 18.097888 │\n",
       "│ 1      ┆ -1.063884 ┆ -3.392264  ┆ -3.437086 ┆ … ┆ -15.099021 ┆ 14.174526 ┆ -5.005744 ┆ -11.08174 │\n",
       "│ 1      ┆ -6.132151 ┆ -0.06236   ┆ 0.309533  ┆ … ┆ 2.676197   ┆ -7.314035 ┆ -5.566668 ┆ -21.80597 │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆           ┆           ┆ 4         │\n",
       "│ 0      ┆ -9.291163 ┆ -1.482626  ┆ -3.096258 ┆ … ┆ -26.425384 ┆ -11.87093 ┆ -1.799935 ┆ -6.94673  │\n",
       "│        ┆           ┆            ┆           ┆   ┆            ┆ 4         ┆           ┆           │\n",
       "└────────┴───────────┴────────────┴───────────┴───┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eager transform.\n",
    "start = perf_counter()\n",
    "res_eager = t.power_transform(df, cols=features, strategy=\"yeo_johnson\")\n",
    "end = perf_counter()\n",
    "print(f\"Spent {end - start:.2f}s in computing.\")\n",
    "res_eager.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import power_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent 7.54s in computing.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>column_0</th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_6</th>\n",
       "      <th>column_7</th>\n",
       "      <th>column_8</th>\n",
       "      <th>...</th>\n",
       "      <th>column_90</th>\n",
       "      <th>column_91</th>\n",
       "      <th>column_92</th>\n",
       "      <th>column_93</th>\n",
       "      <th>column_94</th>\n",
       "      <th>column_95</th>\n",
       "      <th>column_96</th>\n",
       "      <th>column_97</th>\n",
       "      <th>column_98</th>\n",
       "      <th>column_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.015350</td>\n",
       "      <td>0.546501</td>\n",
       "      <td>1.643836</td>\n",
       "      <td>4.002086</td>\n",
       "      <td>7.452206</td>\n",
       "      <td>-9.771592</td>\n",
       "      <td>-1.623333</td>\n",
       "      <td>1.134822</td>\n",
       "      <td>-1.164929</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.686986</td>\n",
       "      <td>4.864902</td>\n",
       "      <td>-12.436880</td>\n",
       "      <td>-2.953840</td>\n",
       "      <td>2.584190</td>\n",
       "      <td>-13.517491</td>\n",
       "      <td>17.649640</td>\n",
       "      <td>10.209761</td>\n",
       "      <td>6.877143</td>\n",
       "      <td>18.462875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.163948</td>\n",
       "      <td>-10.179248</td>\n",
       "      <td>2.415587</td>\n",
       "      <td>-8.265827</td>\n",
       "      <td>0.694511</td>\n",
       "      <td>2.389893</td>\n",
       "      <td>-3.863820</td>\n",
       "      <td>4.370761</td>\n",
       "      <td>-8.504408</td>\n",
       "      <td>...</td>\n",
       "      <td>3.009795</td>\n",
       "      <td>-3.605438</td>\n",
       "      <td>5.828239</td>\n",
       "      <td>0.915098</td>\n",
       "      <td>-3.163691</td>\n",
       "      <td>8.604860</td>\n",
       "      <td>40.117015</td>\n",
       "      <td>-50.426680</td>\n",
       "      <td>0.887741</td>\n",
       "      <td>18.097888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.063884</td>\n",
       "      <td>-3.392264</td>\n",
       "      <td>-3.437086</td>\n",
       "      <td>0.969839</td>\n",
       "      <td>-0.685547</td>\n",
       "      <td>1.438776</td>\n",
       "      <td>-0.437007</td>\n",
       "      <td>-1.250506</td>\n",
       "      <td>10.102604</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.788912</td>\n",
       "      <td>2.453942</td>\n",
       "      <td>-27.491511</td>\n",
       "      <td>3.863301</td>\n",
       "      <td>0.076167</td>\n",
       "      <td>2.649376</td>\n",
       "      <td>-15.099021</td>\n",
       "      <td>14.174526</td>\n",
       "      <td>-5.005744</td>\n",
       "      <td>-11.081740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-6.132151</td>\n",
       "      <td>-0.062360</td>\n",
       "      <td>0.309533</td>\n",
       "      <td>-1.478143</td>\n",
       "      <td>3.192917</td>\n",
       "      <td>0.571616</td>\n",
       "      <td>1.584268</td>\n",
       "      <td>7.196294</td>\n",
       "      <td>-0.907031</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.561316</td>\n",
       "      <td>0.368105</td>\n",
       "      <td>-5.171747</td>\n",
       "      <td>-3.896017</td>\n",
       "      <td>3.374336</td>\n",
       "      <td>-11.443679</td>\n",
       "      <td>2.676197</td>\n",
       "      <td>-7.314035</td>\n",
       "      <td>-5.566668</td>\n",
       "      <td>-21.805974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-9.291163</td>\n",
       "      <td>-1.482626</td>\n",
       "      <td>-3.096258</td>\n",
       "      <td>4.839853</td>\n",
       "      <td>4.798556</td>\n",
       "      <td>3.426212</td>\n",
       "      <td>-0.045949</td>\n",
       "      <td>-6.571324</td>\n",
       "      <td>-0.951256</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.598112</td>\n",
       "      <td>-3.654096</td>\n",
       "      <td>6.314281</td>\n",
       "      <td>1.607791</td>\n",
       "      <td>3.315166</td>\n",
       "      <td>17.225647</td>\n",
       "      <td>-26.425384</td>\n",
       "      <td>-11.870934</td>\n",
       "      <td>-1.799935</td>\n",
       "      <td>-6.946730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  column_0   column_1  column_2  column_3  column_4  column_5   \n",
       "0       1  6.015350   0.546501  1.643836  4.002086  7.452206 -9.771592  \\\n",
       "1       1  4.163948 -10.179248  2.415587 -8.265827  0.694511  2.389893   \n",
       "2       1 -1.063884  -3.392264 -3.437086  0.969839 -0.685547  1.438776   \n",
       "3       1 -6.132151  -0.062360  0.309533 -1.478143  3.192917  0.571616   \n",
       "4       0 -9.291163  -1.482626 -3.096258  4.839853  4.798556  3.426212   \n",
       "\n",
       "   column_6  column_7   column_8  ...  column_90  column_91  column_92   \n",
       "0 -1.623333  1.134822  -1.164929  ...  -1.686986   4.864902 -12.436880  \\\n",
       "1 -3.863820  4.370761  -8.504408  ...   3.009795  -3.605438   5.828239   \n",
       "2 -0.437007 -1.250506  10.102604  ...  -1.788912   2.453942 -27.491511   \n",
       "3  1.584268  7.196294  -0.907031  ...  -4.561316   0.368105  -5.171747   \n",
       "4 -0.045949 -6.571324  -0.951256  ...  -6.598112  -3.654096   6.314281   \n",
       "\n",
       "   column_93  column_94  column_95  column_96  column_97  column_98  column_99  \n",
       "0  -2.953840   2.584190 -13.517491  17.649640  10.209761   6.877143  18.462875  \n",
       "1   0.915098  -3.163691   8.604860  40.117015 -50.426680   0.887741  18.097888  \n",
       "2   3.863301   0.076167   2.649376 -15.099021  14.174526  -5.005744 -11.081740  \n",
       "3  -3.896017   3.374336 -11.443679   2.676197  -7.314035  -5.566668 -21.805974  \n",
       "4   1.607791   3.315166  17.225647 -26.425384 -11.870934  -1.799935  -6.946730  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sklearn with Pandas\n",
    "\n",
    "start = perf_counter()\n",
    "transformed = power_transform(df_pd[features], method = \"yeo-johnson\", standardize=False)\n",
    "end = perf_counter()\n",
    "df_pd[features] = transformed\n",
    "print(f\"Spent {end - start:.2f}s in computing.\")\n",
    "df_pd.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
